{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import allantools as at\n",
    "from typing import Callable, Iterable, Optional, Tuple\n",
    "from functools import partial\n",
    "import functools\n",
    "import inspect\n",
    "from runData import runData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.precision\", 15)      # Show up to 15 decimal places\n",
    "dirName  = 'labData/'\n",
    "#rowLimit = 2000 # Rows to keep after joining ticc and timTp samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Big Picture\n",
    "#   Read TICC data from runs of interest\n",
    "#   Merge TICC channels chA and chB by time\n",
    "#   Process TICC data, do simple analysis without timTp data\n",
    "#   Read timTp data\n",
    "#   Merge timTp channels chA and chB by time\n",
    "#   Merge TICC and timTp data by time\n",
    "#   Plot and analyze results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read TICC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read TAPR TICC data into a dataframe, as captured to a file by ticc.py running on a host.\n",
    "# Events are rising edges of a PPS signal from a DUT, resulting in a timestamp on the TICC's reference clock.\n",
    "# Columns:\n",
    "#  ppsHostClock: Host clock when serial data for PPS event timestamp was read (ticc.py logs this in UTC)\n",
    "#  ppsRefClock:  Reference clock when PPS event happened (elapsed seconds since TICC started)\n",
    "#\n",
    "# The frequency of the TICC reference clock comes from an external 10 MHz source, a Geppetto Electronics GNSSDO in my case.\n",
    "# It should be almost exactly 1e7 times the PPS frequency, with an arbitray phase relationship.\n",
    "# So we expect the whole number portion of ppsRefClock to increment by 1 every second, while the fractional seconds jitter around\n",
    "# some slowly-changing phase offset.\n",
    "# Therefore, there's very little information in the whole seconds, while the fractional seconds contain the most interesting data.\n",
    "# And as the whole number grows with a floating point representation, precision is lost in the fractional digits.\n",
    "# So once we confirm the whole number of seconds is behaving as expected, we can drop it and focus on the fractional seconds.\n",
    "# Whatever slowly-changing phase offset exists, it won't impact the deviation metrics.\n",
    "# We treat the fractional seconds as an instantaneous (but nosiy) measurement of the phase error against the ref clock.\n",
    "#\n",
    "# There is a very small, but non-zero chance that the static phase offset plus the jitter causes sequential PPS timestamps to be\n",
    "# within the same second or more than one second apart, leading to missing or duplicate whole seconds.\n",
    "# Instead of properly handling whole seconds when this happens, just fail on assertions.\n",
    "def readTicc(baseName, chan):\n",
    "    ticcFile = f\"{dirName}/{baseName}.ticc{chan}.csv\"\n",
    "    ticcData = pd.read_csv(ticcFile, dtype={'ppsHostClock': str, 'ppsRefClock': str})\n",
    "\n",
    "    # Convert host timestamp string to UTC timestamp\n",
    "    ticcData[\"ppsHostClock\"] = pd.to_datetime(ticcData.ppsHostClock, utc=True)\n",
    "\n",
    "    # Assuming host clock sync is better than serialization latency of timestamp arriving,\n",
    "    # floor of host clock second will be the navigation epoch sencond.\n",
    "    # Will be used for later join with TIM-TP timestamps.\n",
    "    ticcData[\"epochSec\"] = ticcData[\"ppsHostClock\"].dt.floor(\"s\")\n",
    "\n",
    "\n",
    "    # Split ppsRefClock string into whole and fractional seconds\n",
    "    ticcData[[\"rcWhole\", \"rcFrac\"]] = ticcData.ppsRefClock.str.split(\".\", n=1, expand=True)\n",
    "\n",
    "    # Check for missing or duplicate whole seconds\n",
    "    ticcData['rcWhole'] = ticcData['rcWhole'].astype(int)\n",
    "    expected = set(range(ticcData.rcWhole.min(), ticcData.rcWhole.max() + 1))\n",
    "    observed = set(ticcData.rcWhole)\n",
    "    missing = sorted(expected - observed)\n",
    "    duplicates = ticcData.rcWhole[ticcData.rcWhole.duplicated()].unique().tolist()\n",
    "    assert len(missing)    == 0, f\"Missing whole seconds in ticc{chan}: {missing}\"\n",
    "    assert len(duplicates) == 0, f\"Duplicate whole seconds in ticc{chan}: {duplicates}\"\n",
    "\n",
    "    # Convert ref clock fractional part from digit string to float\n",
    "    ticcData['rcFrac'] = \"0.\" + ticcData['rcFrac'].astype(str)\n",
    "    ticcData['rcFrac'] = ticcData['rcFrac'].astype(float)\n",
    "\n",
    "    # Also get fractional part of host clock\n",
    "    ticcData['hcFrac'] = (ticcData.ppsHostClock.astype('int64')-1e9*(ticcData.ppsHostClock.astype('int64')//1e9))/1e9\n",
    "\n",
    "    # With overly careful consideration of maintining floating point precision, get interval between PPS events on ref clock.\n",
    "    ticcData['rcTi'] = (ticcData.rcWhole-ticcData.rcWhole.shift(1)) + (ticcData.rcFrac - ticcData.rcFrac.shift(1)) # Time interval between refClock samples on ref clock\n",
    "\n",
    "    ticcData['bn'  ] = baseName\n",
    "    ticcData['dut' ] = runData[baseName][chan]\n",
    "    ticcData['chan'] = chan\n",
    "    return ticcData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "dfs.append(readTicc('baseline1', 'A'))\n",
    "dfs.append(readTicc('baseline2', 'A'))\n",
    "dfs.append(readTicc('baseline3', 'A'))\n",
    "dfs.append(readTicc('baseline4', 'A'))\n",
    "dfs.append(readTicc('baseline5', 'A'))\n",
    "\n",
    "dfs.append(readTicc('fixedPos1', 'A'))\n",
    "dfs.append(readTicc('fixedPos2', 'A'))\n",
    "\n",
    "dfs.append(readTicc('fixedL1ca1', 'A'))\n",
    "dfs.append(readTicc('fixedL1ca2', 'A'))\n",
    "\n",
    "dfs.append(readTicc('fixedL1l51', 'A'))\n",
    "dfs.append(readTicc('fixedL1l52', 'A'))\n",
    "dfs.append(readTicc('fixedL1l52', 'B'))\n",
    "dfs.append(readTicc('fixedL1l53', 'A'))\n",
    "dfs.append(readTicc('fixedL1l53', 'B'))\n",
    "\n",
    "dfs.append(readTicc('f9tM600-1', 'A'))\n",
    "dfs.append(readTicc('f9tM600-1', 'B'))\n",
    "dfs.append(readTicc('f9tM600-2', 'A'))\n",
    "dfs.append(readTicc('f9tM600-2', 'B'))\n",
    "ticc = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticc\n",
    "# XXX next step: define function to generate statistics from selected rows of ticc, plot, and label them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge TICC Channels chA and chB Data by Time (Reference Clock Second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring data from TICC channels for each run together for each ref clock second.\n",
    "# Retain epoch second for later join\n",
    "ticcA = ticc[ticc.chan == 'A'][['bn', 'rcWhole', 'rcFrac', 'epochSec']]\n",
    "ticcB = ticc[ticc.chan == 'B'][['bn', 'rcWhole', 'rcFrac'            ]]\n",
    "\n",
    "# Perform inner join on bn and rcWhole\n",
    "rcSec = pd.merge(ticcA, ticcB, on=['bn', 'rcWhole'], how='outer', suffixes=('A', 'B'))\n",
    "\n",
    "# Derive columns of interest from the TICC data.\n",
    "if ticcB.empty:\n",
    "    rcSec.drop(columns=['rcFracB'], inplace=True)\n",
    "else:\n",
    "    rcSec['rcFracAB'] = rcSec.rcFracA - rcSec.rcFracB  # Phase difference between the two channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticcB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcSec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do Simple TICC Data Analysis Without TIM-TP Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX Fixme when run with no channel B\n",
    "beg = 1000\n",
    "end = 2000\n",
    "bn = 'fixedL1l53'\n",
    "plt.figure(figsize=(24, 6))\n",
    "plt.plot(rcSec[rcSec.bn==bn].epochSec[beg:end], rcSec[rcSec.bn==bn].rcFracAB[beg:end]*1e9, marker='.', linestyle='-', color='b')\n",
    "plt.title(f\"Phase Difference (rcFracAB) vs Epoch Second for Run {bn}\")\n",
    "plt.xlabel('Epoch Second')\n",
    "plt.ylabel('Phase Difference (rcFracAB)')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(22, 6))\n",
    "fig.canvas.draw()\n",
    "bbox = ax.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "widthPx = int(bbox.width*fig.dpi)\n",
    "print(\"Figure width in pixels:\", widthPx)\n",
    "print(fig.get_figwidth())\n",
    "for bn in ticc.bn.unique():\n",
    "    ticcSubset = ticc[ticc.bn == bn]\n",
    "    plt.hist(1e9*(ticcSubset.rcTi-1.0), bins=widthPx, label=bn, alpha=0.5)\n",
    "#plt.hist(1e9*(ticc[ticc.bn==bn].rcTi[beg:end]-1.0), bins=widthPx, color='blue', alpha=0.7)\n",
    "plt.title('Histogram of Time Error Between PPS Pulses')\n",
    "plt.xlabel('Time Error (ns)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.legend()\n",
    "plt.gca().xaxis.set_major_formatter(FuncFormatter(lambda y, _: f\"{y:g} ns\"))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read TIM-TP Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTimTp(baseName, chan):\n",
    "    timTp = pd.read_csv(f\"{dirName}/{baseName}.timTp{chan}.csv\")\n",
    "\n",
    "    # Confirm expected values in constant columns, then drop them\n",
    "    assert (timTp['timeBase'   ] ==  1).all(), \"Not all rows in timTp.timeBase are equal to 1\"\n",
    "    assert (timTp['utc'        ] ==  1).all(), \"Not all rows in timTp.utc are equal to 1\"\n",
    "    assert (timTp['raim'       ] ==  2).all(), \"Not all rows in timTp.raim are equal to 2\"\n",
    "    assert (timTp['qErrInvalid'] ==  0).all(), \"Not all rows in timTp.qErrInvalid are equal to 0\"\n",
    "    assert (timTp['TpNotLocked'] ==  0).all(), \"Not all rows in timTp.TpNotLocked are equal to 0\"\n",
    "    assert (timTp['timeRefGnss'] == 15).all(), \"Not all rows in timTp.timeRefGnss are equal to 15\"\n",
    "    assert (timTp['utcStandard'] ==  3).all(), \"Not all rows in timTp.utcStandard are equal to  3\"\n",
    "    assert (timTp['towSubMS'   ] ==  0).all(), \"Not all rows in timTp.towSubMS are equal to  0\"\n",
    "    timTp.drop(columns=['timeBase', 'utc', 'raim', 'qErrInvalid', 'TpNotLocked', 'timeRefGnss', 'utcStandard', 'towSubMS'], inplace=True)\n",
    "\n",
    "    # Constants for time conversion\n",
    "    gps_epoch = pd.Timestamp(\"1980-01-06 00:00:00\", tz=\"UTC\")\n",
    "    leap_seconds = pd.Timedelta(seconds=18)  # current GPS-UTC offset (2025)\n",
    "\n",
    "    # Vectorized conversion from GPS week and TOW to epoch seconds\n",
    "    timTp[\"epochSec\"] = (\n",
    "        gps_epoch\n",
    "        + pd.to_timedelta(timTp.week  * 7, unit=\"D\" )\n",
    "        + pd.to_timedelta(timTp.towMS    , unit=\"ms\")\n",
    "    )\n",
    "    timTp.drop(columns=['week', 'towMS'], inplace=True)\n",
    "\n",
    "    timTp['qErrFrac'] = timTp.qErr/1e12 # Convert qErr from picoseconds to seconds\n",
    "\n",
    "    timTp['bn'] = baseName\n",
    "    timTp['dut' ] = runData[baseName][chan]\n",
    "    timTp['chan'] = chan\n",
    "    return timTp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "dfs.append(readTimTp('baseline1', 'A'))\n",
    "dfs.append(readTimTp('baseline2', 'A'))\n",
    "dfs.append(readTimTp('baseline3', 'A'))\n",
    "dfs.append(readTimTp('baseline4', 'A'))\n",
    "dfs.append(readTimTp('baseline5', 'A'))\n",
    "\n",
    "dfs.append(readTimTp('fixedPos1', 'A'))\n",
    "dfs.append(readTimTp('fixedPos2', 'A'))\n",
    "\n",
    "dfs.append(readTimTp('fixedL1ca1', 'A'))\n",
    "dfs.append(readTimTp('fixedL1ca2', 'A'))\n",
    "\n",
    "dfs.append(readTimTp('fixedL1l51', 'A'))\n",
    "dfs.append(readTimTp('fixedL1l52', 'A'))\n",
    "dfs.append(readTimTp('fixedL1l52', 'B'))\n",
    "dfs.append(readTimTp('fixedL1l53', 'A'))\n",
    "dfs.append(readTimTp('fixedL1l53', 'B'))\n",
    "\n",
    "timTp = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timTp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge TIM-TP Data for Channels chA and chB by Time (Epoch Second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring data from TIM-TP messages for each run together for each epoch second.\n",
    "timTpA = timTp[timTp.chan == 'A'][['bn', 'epochSec', 'qErr', 'qErrFrac']]\n",
    "timTpB = timTp[timTp.chan == 'B'][['bn', 'epochSec', 'qErr', 'qErrFrac']]\n",
    "\n",
    "# Perform inner join on bn and epoch second\n",
    "epSec = pd.merge(timTpA, timTpB, on=['bn', 'epochSec'], how='outer', suffixes=('A', 'B'))\n",
    "#if timTpB.empty:\n",
    "#    epSec.drop(columns=['qErrB'    ], inplace=True)\n",
    "#    epSec.drop(columns=['qErrFracB'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge TICC Data and TIM-TP Data by Time (Epoch Second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge TICC data from above with TIM-TP data on epoch second.\n",
    "epSec = pd.merge(epSec, rcSec, on=['bn', 'epochSec'], how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct rcFrac with qErr\n",
    "epSec['rcFracCorrA'] = epSec.rcFracA+epSec.qErrFracA\n",
    "\n",
    "#if not timTpB.empty:\n",
    "epSec['rcFracCorrB'] = epSec.rcFracB+epSec.qErrFracB\n",
    "# Corrected phase difference between the two channels\n",
    "epSec['rcFracCorrAB'] = epSec.rcFracCorrA - epSec.rcFracCorrB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['rcFracA', 'qErrA', 'qErrFracA', 'rcFracCorrA',\n",
    "           'rcFracB', 'qErrB', 'qErrFracB', 'rcFracCorrB', 'rcFracCorrAB']\n",
    "epSec.groupby('bn')[metrics].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Export to TimeLab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select File->Import phase or frequency data fro ASCII file\n",
    "#   Fill in Caption, Additional, Sampling Interval 1.0 sec, Input Frequency 1 Hz\n",
    "#   Numeric Field 1 x 1.0 = Phase difference (sec), Data Format Decimal\n",
    "expFracs = ['rcFracA', 'rcFracCorrA',\n",
    "           'rcFracB', 'rcFracCorrB', 'rcFracCorrAB']\n",
    "expDir = \"exports\"\n",
    "for bn in epSec.bn.unique():\n",
    "    for expFrac in expFracs:\n",
    "        phaseErr = epSec[epSec.bn == bn][expFrac].dropna()\n",
    "        if len(phaseErr) != 0:\n",
    "            chan = 'foof'\n",
    "            if expFrac[-2:] == 'AB':\n",
    "                chan = f\"{runData[bn]['A']}-{runData[bn]['B']}\"\n",
    "            elif expFrac[-1:] == 'A':\n",
    "                chan = f\"{runData[bn]['A']}\"\n",
    "            elif expFrac[-1:] == 'B':\n",
    "                chan = f\"{runData[bn]['B']}\"\n",
    "            else:\n",
    "                assert False, f\"Unexpected expFrac suffix {expFrac}\"\n",
    "            expFn = f\"{expDir}/{bn}_{expFrac}_{chan}.txt\"\n",
    "            print(f\"{expFn}\")\n",
    "            phaseErr.to_csv(expFn, index=False, header=False, float_format='%.15f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beg = 11000\n",
    "end = 11500\n",
    "bn = 'fixedL1l53'\n",
    "plt.figure(figsize=(24, 6))\n",
    "plt.plot(epSec[epSec.bn==bn].epochSec[beg:end], epSec[epSec.bn==bn].rcFracAB[beg:end]*1e9, marker='.', linestyle='-', color='b')\n",
    "plt.plot(epSec[epSec.bn==bn].epochSec[beg:end], epSec[epSec.bn==bn].rcFracCorrAB[beg:end]*1e9, marker='.', linestyle='-', color='r')\n",
    "plt.title(f\"Phase Difference (epFracAB) vs Epoch Second for Run {bn}\")\n",
    "plt.xlabel('Epoch Second')\n",
    "plt.ylabel('Phase Difference (epFracAB)')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare callables for equality\n",
    "def canonCallable(fn):\n",
    "    g = inspect.unwrap(fn)               # peel decorators that use __wrapped__\n",
    "    while isinstance(g, functools.partial):\n",
    "        g = g.func                       # strip partial layers\n",
    "    return getattr(g, \"__func__\", g)     # bound method → underlying function\n",
    "\n",
    "def sameFunc(a, b):\n",
    "    return canonCallable(a) is canonCallable(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max averaging factor winLen: 3 for TDEV/MDEV, 2 for ADEV\n",
    "def genTaus(n, thresh=25, winLen=3, perDecade=30):\n",
    "    # Conservative τ_max so long-τ points still have usable statistics\n",
    "    # Constants come from watching TimeLab behavior\n",
    "    tauMax = n * 0.2 if winLen == 3 else n * 0.25\n",
    "\n",
    "    # Expected max statistical point returned by the algorithm\n",
    "    maxStat = (n-1) // winLen\n",
    "\n",
    "    m_max_tau = int(np.floor(tauMax)) # XXXX Don't love this\n",
    "    m_max = max(1, min(maxStat, m_max_tau))\n",
    "\n",
    "    m_switch = max(1, int(np.floor(thresh)))\n",
    "    denseTaus = np.arange(1, min(m_switch, m_max) + 1, dtype=int)\n",
    "\n",
    "    if m_switch < m_max:\n",
    "        # geometric spacing after the switch\n",
    "        decades = max(1, int(np.ceil(np.log10(m_max) - np.log10(m_switch + 1))))\n",
    "        m_geo = np.unique(np.rint(\n",
    "            np.geomspace(m_switch + 1, m_max, decades * perDecade)\n",
    "        ).astype(int))\n",
    "        taus = np.unique(np.r_[denseTaus, m_geo])\n",
    "    else:\n",
    "        taus = denseTaus\n",
    "\n",
    "    return taus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapters — Wrap allantools functions to match StatFn signature.\n",
    "# Tip: use functools.partial to pre-set rate, data_type, taus, overlapping, etc.\n",
    "\n",
    "# Type: any callable that takes your prepared data and returns (taus, values, errors_or_None)\n",
    "StatFn = Callable[[np.ndarray], Tuple[np.ndarray, np.ndarray, Optional[np.ndarray]]]\n",
    "\n",
    "\n",
    "def wrap_adev(rate: float = 1.0, data_type: str = \"phase\", taus: Optional[Iterable[float]] = None, **kwargs) -> StatFn:\n",
    "    \"\"\"\n",
    "    Returns a callable that takes 'data' and produces (taus, values, errors_or_None, n).\n",
    "    \"\"\"\n",
    "    def _fn(data: np.ndarray) -> Tuple[np.ndarray, np.ndarray, Optional[np.ndarray]]:\n",
    "        # Many versions return a tuple: (taus, stat, stat_err, ns)\n",
    "        # If yours returns a dict, adjust the extraction below accordingly.\n",
    "        out = at.adev(data, rate=rate, data_type=data_type, taus=genTaus(len(data), winLen=2), **kwargs)\n",
    "        try:\n",
    "            tau, val, err, n = out  # common tuple form\n",
    "        except Exception:\n",
    "            # Fallback for dict-like forms; update keys to match your version\n",
    "            tau = np.asarray(out.get(\"taus\") or out.get(\"tau\"))\n",
    "            val = np.asarray(out.get(\"adev\") or out.get(\"adev\") or out.get(\"values\"))\n",
    "            err = out.get(\"adev_err\") or out.get(\"adeverror\") or None\n",
    "            if err is not None:\n",
    "                err = np.asarray(err)\n",
    "        return np.asarray(tau), np.asarray(val), (None if err is None else np.asarray(err)), n\n",
    "    return _fn\n",
    "\n",
    "adev = wrap_adev()\n",
    "\n",
    "def wrap_oadev(rate: float = 1.0, data_type: str = \"phase\", taus: Optional[Iterable[float]] = None, **kwargs) -> StatFn:\n",
    "    \"\"\"\n",
    "    Returns a callable that takes 'data' and produces (taus, values, errors_or_None, n).\n",
    "    \"\"\"\n",
    "    def _fn(data: np.ndarray) -> Tuple[np.ndarray, np.ndarray, Optional[np.ndarray]]:\n",
    "        out = at.oadev(data, rate=rate, data_type=data_type, taus=genTaus(len(data), winLen=2), **kwargs)\n",
    "        try:\n",
    "            tau, val, err, n = out  # common tuple form\n",
    "        except Exception:\n",
    "            # Fallback for dict-like forms; update keys to match your version\n",
    "            tau = np.asarray(out.get(\"taus\") or out.get(\"tau\"))\n",
    "            val = np.asarray(out.get(\"oadev\") or out.get(\"adev\") or out.get(\"values\"))\n",
    "            err = out.get(\"oadev_err\") or out.get(\"adeverror\") or None\n",
    "            if err is not None:\n",
    "                err = np.asarray(err)\n",
    "        return np.asarray(tau), np.asarray(val), (None if err is None else np.asarray(err)), n\n",
    "    return _fn\n",
    "\n",
    "oadev = wrap_oadev()\n",
    "\n",
    "def wrap_tdev(**kwargs) -> StatFn:\n",
    "    def _fn(data: np.ndarray):\n",
    "        out = at.tdev(data, rate=1.0, taus=genTaus(len(data), perDecade=30), **kwargs)\n",
    "        try:\n",
    "            tau, val, err, n = out\n",
    "        except Exception:\n",
    "            tau = np.asarray(out.get(\"taus\") or out.get(\"tau\"))\n",
    "            val = np.asarray(out.get(\"tdev\") or out.get(\"values\"))\n",
    "            err = out.get(\"tdev_err\") or None\n",
    "            if err is not None:\n",
    "                err = np.asarray(err)\n",
    "        return np.asarray(tau), np.asarray(val), (None if err is None else np.asarray(err)), n\n",
    "    return _fn\n",
    "\n",
    "tdev = wrap_tdev()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statPlotStart(\n",
    "    title: Optional[str] = None,\n",
    "    xlabel: str = r\"$\\tau$\",\n",
    "    ylabel: Optional[str] = r\"$\\sigma_x(\\tau)$\",\n",
    "    logx: bool = True,\n",
    "    logy: bool = True,\n",
    "    grid: bool = True,\n",
    "    figsize: Tuple[float, float] = (16, 9),\n",
    ") -> Tuple[plt.Figure, plt.Axes]:\n",
    "\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    if logx and logy:\n",
    "        ax.set_xscale(\"log\")\n",
    "        ax.set_yscale(\"log\")\n",
    "    elif logx:\n",
    "        ax.set_xscale(\"log\")\n",
    "    elif logy:\n",
    "        ax.set_yscale(\"log\")\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    if ylabel:\n",
    "        ax.set_ylabel(ylabel)\n",
    "    if grid:\n",
    "        ax.grid(True, which=\"both\", alpha=0.35)\n",
    "\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statPlotTrace(\n",
    "    ax: plt.Axes,\n",
    "    s: pd.Series,\n",
    "    stat_fn: StatFn,\n",
    "    secLimit: Optional[int] = sys.maxsize,\n",
    "    *,\n",
    "    label: Optional[str] = None,\n",
    "    errBars: bool = False,\n",
    "    # Matplotlib styling (pass whatever you like; e.g., color, linestyle, marker, alpha, linewidth ...)\n",
    "    **line_kwargs,\n",
    ") -> Tuple[np.ndarray, np.ndarray, Optional[np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Preprocesses the Series, calls stat_fn, then plots (taus, value) on ax.\n",
    "    Returns (taus, values, errors_or_None) for further use if needed.\n",
    "    \"\"\"\n",
    "    taus, vals, errs, n = stat_fn(s[:secLimit].dropna())  # Apply the statistic function to the Series, limited by secLimit\n",
    "\n",
    "    mult = 1e9 if sameFunc(stat_fn, tdev) else 1.0  # Convert to nanoseconds if using TDEV\n",
    "    line = plt.loglog(taus, mult*vals, label=label, **line_kwargs)[0]\n",
    "    color = line.get_color()\n",
    "\n",
    "    if errBars:\n",
    "        goodN = n >= 10 # Ensure we have enough data points for the statistic to be meaningful\n",
    "        ax.errorbar(taus[goodN], mult*vals[goodN], yerr=mult*errs[goodN] if errs is not None else None, fmt='none', color=color, elinewidth=1.4,       # “web” thickness\n",
    "                capsize=2,            # “flange” length\n",
    "                capthick=1.4, **line_kwargs)\n",
    "    return taus, vals, errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statPlotFinish(\n",
    "    ax: plt.Axes,\n",
    "    stat_fn: Optional[StatFn] = tdev,\n",
    "    legend: bool = True,\n",
    "    legend_loc: str = \"best\",\n",
    "    tight_layout: bool = False,\n",
    "):\n",
    "    if legend:\n",
    "        ax.legend(loc=legend_loc)\n",
    "    if tight_layout:\n",
    "        ax.figure.tight_layout()\n",
    "\n",
    "    #plt.annotate(f\"Uncorrected TDEV(1 s): {tdevUcNs[0]:.3f} ns\", xy=(1, tdevUcNs[0]), xytext=(1.1, 3),\n",
    "    #            arrowprops=dict(arrowstyle=\"fancy\", ec=\"black\", fc=\"yellow\", lw=0.5))\n",
    "    #plt.annotate(f\"Corrected TDEV(1 s): {tdevCorrNs[0]:.3f} ns\", xy=(1, tdevCorrNs[0]), xytext=(1.1, 0.25),\n",
    "    #            arrowprops=dict(arrowstyle=\"fancy\", ec=\"black\", fc=\"yellow\", lw=0.5))\n",
    "\n",
    "    plt.grid(which=\"major\", linestyle=\"-\" , linewidth=1.0, color=\"gray\"     )\n",
    "    plt.grid(which=\"minor\", linestyle=\"--\", linewidth=1.0, color=\"lightgray\")\n",
    "\n",
    "    plt.gca().xaxis.set_major_formatter(FuncFormatter(lambda x, _: f\"{x:g} s\"))\n",
    "\n",
    "    if sameFunc(stat_fn, tdev): # XXX need other functions to check\n",
    "        plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda y, _: f\"{y:g} ns\"))\n",
    "\n",
    "        # Shade noise floor\n",
    "        ymin, ymax = plt.ylim() # Save limits before shading\n",
    "        yShadeMin = ymin\n",
    "        yShadeMax = 0.1\n",
    "        plt.axhspan(yShadeMin, yShadeMax, color=\"lightgray\", alpha=0.3)\n",
    "\n",
    "        # Add label centered inside shaded region, remembering that geometric mean is midpoint on log scales\n",
    "        y_center = np.sqrt(yShadeMin * yShadeMax)  # geometric mean for log scale\n",
    "        x_center = np.sqrt(plt.xlim()[0] * plt.xlim()[1])  # vertical center in log scale\n",
    "        plt.text(\n",
    "            x_center, y_center, \"RMS Jitter Floor of TAPR TICC\",\n",
    "            ha=\"center\", va=\"center\",\n",
    "            fontsize=10, color=\"black\",\n",
    "            bbox=dict(facecolor=\"white\", alpha=0.7, edgecolor=\"none\")\n",
    "        )\n",
    "        plt.ylim(ymin, ymax) # Restore limits after shading\n",
    "\n",
    "        plt.text(\n",
    "            0.95, 0.1,                # X & Y position in axes fraction (0–1)\n",
    "            \"Instrument: TAPR TICC\\nReference: Geppetto GPSDO with OH300 5ppb OCXO\",\n",
    "            ha=\"right\", va=\"bottom\",   # Align to lower-right corner\n",
    "            multialignment=\"left\",\n",
    "            transform=plt.gca().transAxes,  # ✅ Use axes fraction (not data coords)\n",
    "            fontsize=10,\n",
    "            bbox=dict(\n",
    "                facecolor=\"white\",     # Background color\n",
    "                edgecolor=\"black\",     # Border color\n",
    "                boxstyle=\"round,pad=0.3\"  # Rounded box with padding\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = statPlotStart(title = r\"Impact of u-blox F9T $\\mathtt{qErr}$ Corrections on TDEV($\\tau$)\")\n",
    "\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedPos1'].rcFracA    , tdev, secLimit=200000, label='Uncorrected', linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedPos1'].rcFracCorrA, tdev, secLimit=200000, label='Corrected'  , linestyle='-', linewidth=2)\n",
    "statPlotFinish(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = statPlotStart(title = r\"Impact of u-blox F9T $\\mathtt{qErr}$ Corrections on OADEV($\\tau$)\")\n",
    "\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedPos1'].rcFracA    , oadev, secLimit=200000, label='Uncorrected', linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedPos1'].rcFracCorrA, oadev, secLimit=200000, label='Corrected'  , linestyle='-', linewidth=2)\n",
    "statPlotFinish(ax, oadev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = statPlotStart(title = r\"Comparing TDEV for Two u-blox F9Ts with Common Anntenna and $\\mathtt{qErr}$ Corrections Individually and to Each Other\")\n",
    "\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracCorrA,  tdev, secLimit=30000, label='F9T-Bob'  , linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracCorrB,  tdev, secLimit=30000, label='F9T-PT'  , linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracCorrAB, tdev, secLimit=30000, label='F9T-Bob vs F9T-PT'  , linestyle='-', linewidth=2)\n",
    "statPlotFinish(ax)\n",
    "# XXX next step: figure out why function pointer comparisions don't work for the default case here\n",
    "# XXX run ADEV on more data sets\n",
    "# Comapre ADEV to other reported results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = statPlotStart(title = r\"Comparing ADEV for Two u-blox F9Ts with Common Anntenna and $\\mathtt{qErr}$ Corrections Individually and to Each Other\")\n",
    "\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracCorrA,  oadev, secLimit=30000, label='F9T-Bob'  , linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracCorrB,  oadev, secLimit=30000, label='F9T-PT'  , linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracCorrAB, oadev, secLimit=30000, label='F9T-Bob vs F9T-PT'  , linestyle='-', linewidth=2)\n",
    "statPlotFinish(ax, oadev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = statPlotStart(title = r\"Comparing TDEV for u-blox F9T and Meinberg M600 DHQ\")\n",
    "\n",
    "statPlotTrace(ax, epSec[epSec.bn=='f9tM600-2' ].rcFracB,     tdev, secLimit=300000, label='M600 DHQ'  , linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracA    , tdev, secLimit=300000, label='Uncorrected F9T-Bob', linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracCorrA, tdev, secLimit=300000, label='Corrected F9T-Bob'  , linestyle='dotted', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracB    , tdev, secLimit=300000, label='Uncorrected F9T-PT', linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracCorrB, tdev, secLimit=300000, label='Corrected F9T-PT'  , linestyle='dotted', linewidth=2)\n",
    "statPlotFinish(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = statPlotStart(title = r\"Comparing ADEV for u-blox F9T and Meinberg M600 DHQ\")\n",
    "\n",
    "statPlotTrace(ax, epSec[epSec.bn=='f9tM600-2' ].rcFracB,     oadev, secLimit=300000, label='M600 DHQ'  , linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracA    , oadev, secLimit=300000, label='Uncorrected F9T-Bob', linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracCorrA, oadev, secLimit=300000, label='Corrected F9T-Bob'  , linestyle='dotted', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracB    , oadev, secLimit=300000, label='Uncorrected F9T-PT', linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracCorrB, oadev, secLimit=300000, label='Corrected F9T-PT'  , linestyle='dotted', linewidth=2)\n",
    "statPlotFinish(ax, oadev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = statPlotStart(title = r\"Comparing TDEV u-blox F9T as Config is Improved for Timing Performance\")\n",
    "\n",
    "statPlotTrace(ax, epSec[epSec.bn=='baseline5' ].rcFracA,     tdev, secLimit=300000, label='Factory Reset, Config Cleared'  , linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1ca1'].rcFracA    , tdev, secLimit=300000, label='Fixed Position L1 C/A, Run 1', linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracA    , tdev, secLimit=300000, label='Fixed Position L1 C/A & L5, Run 3', linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracCorrA, tdev, secLimit=300000, label='Fixed Position L1 C/A & L5, qErr Corrected'  , linestyle='dotted', linewidth=2)\n",
    "statPlotFinish(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = statPlotStart(title = r\"Comparing ADEV u-blox F9T as Config is Improved for Timing Performance\")\n",
    "\n",
    "statPlotTrace(ax, epSec[epSec.bn=='baseline5' ].rcFracA,     oadev, secLimit=300000, label='Factory Reset, Config Cleared'  , linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1ca1'].rcFracA    , oadev, secLimit=300000, label='Fixed Position L1 C/A, Run 1', linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracA    , oadev, secLimit=300000, label='Fixed Position L1 C/A & L5, Run 3', linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracCorrA, oadev, secLimit=300000, label='Fixed Position L1 C/A & L5, qErr Corrected'  , linestyle='dotted', linewidth=2)\n",
    "statPlotFinish(ax, oadev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX Next: clear output and checkpoint to git\n",
    "# Try ADEV and MTIE\n",
    "# . Plot M600\n",
    "# Collect data on CNS Clock\n",
    "# Compare to baseline 5 without fixed position\n",
    "# Confirm export to Timelab produces comparable plots\n",
    "# Collecte data on AliExpress OCXO\n",
    "# Review other devices in talk proposal for data collection\n",
    "# Study time error histograms more carefully\n",
    "# Can you get error bars on TDEV and other plots?\n",
    "# Get deeper understanding of different deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epSec[epSec.bn=='ft9M600-2'].rcFracB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rcSec.bn.unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
