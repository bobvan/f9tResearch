{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter, MaxNLocator\n",
    "import allantools as at\n",
    "from typing import Callable, Iterable, Optional, Tuple\n",
    "from functools import partial\n",
    "import functools\n",
    "import inspect\n",
    "from runData import runData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.precision\", 15)      # Show up to 15 decimal places\n",
    "dirName  = 'labData/'\n",
    "#rowLimit = 2000 # Rows to keep after joining ticc and timTp samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Big Picture\n",
    "#   Read TICC data from runs of interest\n",
    "#   Merge TICC channels chA and chB by time\n",
    "#   Process TICC data, do simple analysis without timTp data\n",
    "#   Read timTp data\n",
    "#   Merge timTp channels chA and chB by time\n",
    "#   Merge TICC and timTp data by time\n",
    "#   Plot and analyze results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read TICC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read TAPR TICC data into a dataframe, as captured to a file by ticc.py running on a host.\n",
    "# Events are rising edges of a PPS signal from a DUT, resulting in a timestamp on the TICC's reference clock.\n",
    "# Columns:\n",
    "#  ppsHostClock: Host clock when serial data for PPS event timestamp was read (ticc.py logs this in UTC)\n",
    "#  ppsRefClock:  Reference clock when PPS event happened (elapsed seconds since TICC started)\n",
    "#\n",
    "# The frequency of the TICC reference clock comes from an external 10 MHz source, a Geppetto Electronics GNSSDO in my case.\n",
    "# It should be almost exactly 1e7 times the PPS frequency, with an arbitray phase relationship.\n",
    "# So we expect the whole number portion of ppsRefClock to increment by 1 every second, while the fractional seconds jitter around\n",
    "# some slowly-changing phase offset.\n",
    "# Therefore, there's very little information in the whole seconds, while the fractional seconds contain the most interesting data.\n",
    "# And as the whole number grows with a floating point representation, precision is lost in the fractional digits.\n",
    "# So once we confirm the whole number of seconds is behaving as expected, we can drop it and focus on the fractional seconds.\n",
    "# Whatever slowly-changing phase offset exists, it won't impact the deviation metrics.\n",
    "# We treat the fractional seconds as an instantaneous (but nosiy) measurement of the phase error against the ref clock.\n",
    "#\n",
    "# There is a very small, but non-zero chance that the static phase offset plus the jitter causes sequential PPS timestamps to be\n",
    "# within the same second or more than one second apart, leading to missing or duplicate whole seconds.\n",
    "# Instead of properly handling whole seconds when this happens, just fail on assertions.\n",
    "def readTicc(baseName, chan):\n",
    "    ticcFile = f\"{dirName}/{baseName}.ticc{chan}.csv\"\n",
    "    ticcData = pd.read_csv(ticcFile, dtype={'ppsHostClock': str, 'ppsRefClock': str})\n",
    "\n",
    "    # Convert host timestamp string to UTC timestamp\n",
    "    ticcData[\"ppsHostClock\"] = pd.to_datetime(ticcData.ppsHostClock, utc=True)\n",
    "\n",
    "    # Assuming host clock sync is better than serialization latency of timestamp arriving,\n",
    "    # floor of host clock second will be the navigation epoch sencond.\n",
    "    # Will be used for later join with TIM-TP timestamps.\n",
    "    ticcData[\"epochSec\"] = ticcData[\"ppsHostClock\"].dt.floor(\"s\")\n",
    "\n",
    "\n",
    "    # Split ppsRefClock string into whole and fractional seconds\n",
    "    ticcData[[\"rcWhole\", \"rcFrac\"]] = ticcData.ppsRefClock.str.split(\".\", n=1, expand=True)\n",
    "\n",
    "    # Check for missing or duplicate whole seconds\n",
    "    ticcData['rcWhole'] = ticcData['rcWhole'].astype(int)\n",
    "    expected = set(range(ticcData.rcWhole.min(), ticcData.rcWhole.max() + 1))\n",
    "    observed = set(ticcData.rcWhole)\n",
    "    missing = sorted(expected - observed)\n",
    "    duplicates = ticcData.rcWhole[ticcData.rcWhole.duplicated()].unique().tolist()\n",
    "    assert len(missing)    == 0, f\"Missing whole seconds in ticc{chan}: {missing}\"\n",
    "    assert len(duplicates) == 0, f\"Duplicate whole seconds in ticc{chan}: {duplicates}\"\n",
    "\n",
    "    # Convert ref clock fractional part from digit string to float\n",
    "    ticcData['rcFrac'] = \"0.\" + ticcData['rcFrac'].astype(str)\n",
    "    ticcData['rcFrac'] = ticcData['rcFrac'].astype(float)\n",
    "\n",
    "    # Also get fractional part of host clock\n",
    "    ticcData['hcFrac'] = (ticcData.ppsHostClock.astype('int64')-1e9*(ticcData.ppsHostClock.astype('int64')//1e9))/1e9\n",
    "\n",
    "    # With overly careful consideration of maintining floating point precision, get interval between PPS events on ref clock.\n",
    "    ticcData['rcTi'] = (ticcData.rcWhole-ticcData.rcWhole.shift(1)) + (ticcData.rcFrac - ticcData.rcFrac.shift(1)) # Time interval between refClock samples on ref clock\n",
    "\n",
    "    ticcData['bn'  ] = baseName\n",
    "    ticcData['dut' ] = runData[baseName][chan]\n",
    "    ticcData['chan'] = chan\n",
    "    return ticcData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "dfs.append(readTicc('baseline1', 'A'))\n",
    "dfs.append(readTicc('baseline2', 'A'))\n",
    "dfs.append(readTicc('baseline3', 'A'))\n",
    "dfs.append(readTicc('baseline4', 'A'))\n",
    "dfs.append(readTicc('baseline5', 'A'))\n",
    "\n",
    "dfs.append(readTicc('fixedPos1', 'A'))\n",
    "dfs.append(readTicc('fixedPos2', 'A'))\n",
    "\n",
    "dfs.append(readTicc('fixedL1ca1', 'A'))\n",
    "dfs.append(readTicc('fixedL1ca2', 'A'))\n",
    "\n",
    "dfs.append(readTicc('fixedL1l51', 'A'))\n",
    "dfs.append(readTicc('fixedL1l52', 'A'))\n",
    "dfs.append(readTicc('fixedL1l52', 'B'))\n",
    "dfs.append(readTicc('fixedL1l53', 'A'))\n",
    "dfs.append(readTicc('fixedL1l53', 'B'))\n",
    "\n",
    "dfs.append(readTicc('f9tM600-1', 'A'))\n",
    "dfs.append(readTicc('f9tM600-1', 'B'))\n",
    "dfs.append(readTicc('f9tM600-2', 'A'))\n",
    "dfs.append(readTicc('f9tM600-2', 'B'))\n",
    "\n",
    "dfs.append(readTicc('ctiCns1', 'A'))\n",
    "dfs.append(readTicc('ctiCns1', 'B'))\n",
    "\n",
    "ticc = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge TICC Channels chA and chB Data by Time (Reference Clock Second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring data from TICC channels for each run together for each ref clock second.\n",
    "# Retain epoch second for later join\n",
    "ticcA = ticc[ticc.chan == 'A'][['bn', 'rcWhole', 'rcFrac', 'epochSec']]\n",
    "ticcB = ticc[ticc.chan == 'B'][['bn', 'rcWhole', 'rcFrac'            ]]\n",
    "\n",
    "# Perform inner join on bn and rcWhole\n",
    "rcSec = pd.merge(ticcA, ticcB, on=['bn', 'rcWhole'], how='outer', suffixes=('A', 'B'))\n",
    "\n",
    "# Derive columns of interest from the TICC data.\n",
    "if ticcB.empty:\n",
    "    rcSec.drop(columns=['rcFracB'], inplace=True)\n",
    "else:\n",
    "    rcSec['rcFracAB'] = rcSec.rcFracA - rcSec.rcFracB  # Phase difference between the two channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do Simple TICC Data Analysis Without TIM-TP Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX Fixme when run with no channel B\n",
    "beg = 1000\n",
    "end = 2000\n",
    "bn = 'fixedL1l53'\n",
    "plt.figure(figsize=(24, 6))\n",
    "plt.plot(rcSec[rcSec.bn==bn].epochSec[beg:end], rcSec[rcSec.bn==bn].rcFracAB[beg:end]*1e9, marker='.', linestyle='-', color='b')\n",
    "plt.title(f\"Phase Difference (rcFracAB) vs Epoch Second for Run {bn}\")\n",
    "plt.xlabel('Epoch Second')\n",
    "plt.ylabel('Phase Difference (rcFracAB)')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(22, 6))\n",
    "fig.canvas.draw()\n",
    "bbox = ax.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "widthPx = int(bbox.width*fig.dpi)\n",
    "print(\"Figure width in pixels:\", widthPx)\n",
    "print(fig.get_figwidth())\n",
    "for bn in ticc.bn.unique():\n",
    "    ticcSubset = ticc[ticc.bn == bn]\n",
    "    plt.hist(1e9*(ticcSubset.rcTi-1.0), bins=widthPx, label=bn, alpha=0.5)\n",
    "#plt.hist(1e9*(ticc[ticc.bn==bn].rcTi[beg:end]-1.0), bins=widthPx, color='blue', alpha=0.7)\n",
    "plt.title('Histogram of Time Error Between PPS Pulses')\n",
    "plt.xlabel('Time Error (ns)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.legend()\n",
    "plt.gca().xaxis.set_major_formatter(FuncFormatter(lambda y, _: f\"{y:g} ns\"))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read TIM-TP Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTimTp(baseName, chan):\n",
    "    timTp = pd.read_csv(f\"{dirName}/{baseName}.timTp{chan}.csv\")\n",
    "\n",
    "    # Confirm expected values in constant columns, then drop them\n",
    "    assert (timTp['timeBase'   ] ==  1).all(), \"Not all rows in timTp.timeBase are equal to 1\"\n",
    "    assert (timTp['utc'        ] ==  1).all(), \"Not all rows in timTp.utc are equal to 1\"\n",
    "    assert (timTp['raim'       ] ==  2).all(), \"Not all rows in timTp.raim are equal to 2\"\n",
    "    assert (timTp['qErrInvalid'] ==  0).all(), \"Not all rows in timTp.qErrInvalid are equal to 0\"\n",
    "    assert (timTp['TpNotLocked'] ==  0).all(), \"Not all rows in timTp.TpNotLocked are equal to 0\"\n",
    "    assert (timTp['timeRefGnss'] == 15).all(), \"Not all rows in timTp.timeRefGnss are equal to 15\"\n",
    "    assert (timTp['utcStandard'] ==  3).all(), \"Not all rows in timTp.utcStandard are equal to  3\"\n",
    "    assert (timTp['towSubMS'   ] ==  0).all(), \"Not all rows in timTp.towSubMS are equal to  0\"\n",
    "    timTp.drop(columns=['timeBase', 'utc', 'raim', 'qErrInvalid', 'TpNotLocked', 'timeRefGnss', 'utcStandard', 'towSubMS'], inplace=True)\n",
    "\n",
    "    # Constants for time conversion\n",
    "    gps_epoch = pd.Timestamp(\"1980-01-06 00:00:00\", tz=\"UTC\")\n",
    "    leap_seconds = pd.Timedelta(seconds=18)  # current GPS-UTC offset (2025)\n",
    "\n",
    "    # Vectorized conversion from GPS week and TOW to epoch seconds\n",
    "    timTp[\"epochSec\"] = (\n",
    "        gps_epoch\n",
    "        + pd.to_timedelta(timTp.week  * 7, unit=\"D\" )\n",
    "        + pd.to_timedelta(timTp.towMS    , unit=\"ms\")\n",
    "    )\n",
    "    timTp.drop(columns=['week', 'towMS'], inplace=True)\n",
    "\n",
    "    timTp['qErrFrac'] = timTp.qErr/1e12 # Convert qErr from picoseconds to seconds\n",
    "\n",
    "    timTp['bn'] = baseName\n",
    "    timTp['dut' ] = runData[baseName][chan]\n",
    "    timTp['chan'] = chan\n",
    "    return timTp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "dfs.append(readTimTp('baseline1', 'A'))\n",
    "dfs.append(readTimTp('baseline2', 'A'))\n",
    "dfs.append(readTimTp('baseline3', 'A'))\n",
    "dfs.append(readTimTp('baseline4', 'A'))\n",
    "dfs.append(readTimTp('baseline5', 'A'))\n",
    "\n",
    "dfs.append(readTimTp('fixedPos1', 'A'))\n",
    "dfs.append(readTimTp('fixedPos2', 'A'))\n",
    "\n",
    "dfs.append(readTimTp('fixedL1ca1', 'A'))\n",
    "dfs.append(readTimTp('fixedL1ca2', 'A'))\n",
    "\n",
    "dfs.append(readTimTp('fixedL1l51', 'A'))\n",
    "dfs.append(readTimTp('fixedL1l52', 'A'))\n",
    "dfs.append(readTimTp('fixedL1l52', 'B'))\n",
    "dfs.append(readTimTp('fixedL1l53', 'A'))\n",
    "dfs.append(readTimTp('fixedL1l53', 'B'))\n",
    "\n",
    "timTp = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timTp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge TIM-TP Data for Channels chA and chB by Time (Epoch Second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring data from TIM-TP messages for each run together for each epoch second.\n",
    "timTpA = timTp[timTp.chan == 'A'][['bn', 'epochSec', 'qErr', 'qErrFrac']]\n",
    "timTpB = timTp[timTp.chan == 'B'][['bn', 'epochSec', 'qErr', 'qErrFrac']]\n",
    "\n",
    "# Perform inner join on bn and epoch second\n",
    "epSec = pd.merge(timTpA, timTpB, on=['bn', 'epochSec'], how='outer', suffixes=('A', 'B'))\n",
    "#if timTpB.empty:\n",
    "#    epSec.drop(columns=['qErrB'    ], inplace=True)\n",
    "#    epSec.drop(columns=['qErrFracB'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge TICC Data and TIM-TP Data by Time (Epoch Second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge TICC data from above with TIM-TP data on epoch second.\n",
    "epSec = pd.merge(epSec, rcSec, on=['bn', 'epochSec'], how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct rcFrac with qErr\n",
    "epSec['rcFracCorrA'] = epSec.rcFracA+epSec.qErrFracA\n",
    "\n",
    "#if not timTpB.empty:\n",
    "epSec['rcFracCorrB'] = epSec.rcFracB+epSec.qErrFracB\n",
    "# Corrected phase difference between the two channels\n",
    "epSec['rcFracCorrAB'] = epSec.rcFracCorrA - epSec.rcFracCorrB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Per-Second Metrics for each Collection Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['rcFracA', 'qErrA', 'qErrFracA', 'rcFracCorrA',\n",
    "           'rcFracB', 'qErrB', 'qErrFracB', 'rcFracCorrB', 'rcFracCorrAB']\n",
    "epSec.groupby('bn')[metrics].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Export to TimeLab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select File->Import phase or frequency data fro ASCII file\n",
    "#   Fill in Caption, Additional, Sampling Interval 1.0 sec, Input Frequency 1 Hz\n",
    "#   Numeric Field 1 x 1.0 = Phase difference (sec), Data Format Decimal\n",
    "expFracs = ['rcFracA', 'rcFracCorrA',\n",
    "           'rcFracB', 'rcFracCorrB', 'rcFracCorrAB']\n",
    "expDir = \"exports\"\n",
    "for bn in epSec.bn.unique():\n",
    "    for expFrac in expFracs:\n",
    "        phaseErr = epSec[epSec.bn == bn][expFrac].dropna()\n",
    "        if len(phaseErr) != 0:\n",
    "            chan = 'foof'\n",
    "            if expFrac[-2:] == 'AB':\n",
    "                chan = f\"{runData[bn]['A']}-{runData[bn]['B']}\"\n",
    "            elif expFrac[-1:] == 'A':\n",
    "                chan = f\"{runData[bn]['A']}\"\n",
    "            elif expFrac[-1:] == 'B':\n",
    "                chan = f\"{runData[bn]['B']}\"\n",
    "            else:\n",
    "                assert False, f\"Unexpected expFrac suffix {expFrac}\"\n",
    "            expFn = f\"{expDir}/{bn}_{expFrac}_{chan}.txt\"\n",
    "            print(f\"{expFn}\")\n",
    "            phaseErr.to_csv(expFn, index=False, header=False, float_format='%.15f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beg = 11000\n",
    "end = 11500\n",
    "bn = 'fixedL1l53'\n",
    "plt.figure(figsize=(24, 6))\n",
    "plt.plot(epSec[epSec.bn==bn].epochSec[beg:end], epSec[epSec.bn==bn].rcFracAB[beg:end]*1e9, marker='.', linestyle='-', color='b')\n",
    "plt.plot(epSec[epSec.bn==bn].epochSec[beg:end], epSec[epSec.bn==bn].rcFracCorrAB[beg:end]*1e9, marker='.', linestyle='-', color='r')\n",
    "plt.title(f\"Phase Difference (epFracAB) vs Epoch Second for Run {bn}\")\n",
    "plt.xlabel('Epoch Second')\n",
    "plt.ylabel('Phase Difference (epFracAB)')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare callables for equality\n",
    "def canonCallable(fn):\n",
    "    g = inspect.unwrap(fn)               # peel decorators that use __wrapped__\n",
    "    while isinstance(g, functools.partial):\n",
    "        g = g.func                       # strip partial layers\n",
    "    return getattr(g, \"__func__\", g)     # bound method → underlying function\n",
    "\n",
    "def sameFunc(a, b):\n",
    "    return canonCallable(a) is canonCallable(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max averaging factor winLen: 3 for TDEV/MDEV, 2 for ADEV\n",
    "def genTaus(n, thresh=25, winLen=3, perDecade=30):\n",
    "    # Conservative τ_max so long-τ points still have usable statistics\n",
    "    # Constants come from watching TimeLab behavior\n",
    "    tauMax = n * 0.2 if winLen == 3 else n * 0.25\n",
    "\n",
    "    # Expected max statistical point returned by the algorithm\n",
    "    maxStat = (n-1) // winLen\n",
    "\n",
    "    m_max_tau = int(np.floor(tauMax)) # XXXX Don't love this\n",
    "    m_max = max(1, min(maxStat, m_max_tau))\n",
    "\n",
    "    m_switch = max(1, int(np.floor(thresh)))\n",
    "    denseTaus = np.arange(1, min(m_switch, m_max) + 1, dtype=int)\n",
    "\n",
    "    if m_switch < m_max:\n",
    "        # geometric spacing after the switch\n",
    "        decades = max(1, int(np.ceil(np.log10(m_max) - np.log10(m_switch + 1))))\n",
    "        m_geo = np.unique(np.rint(\n",
    "            np.geomspace(m_switch + 1, m_max, decades * perDecade)\n",
    "        ).astype(int))\n",
    "        taus = np.unique(np.r_[denseTaus, m_geo])\n",
    "    else:\n",
    "        taus = denseTaus\n",
    "\n",
    "    return taus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapters — Wrap allantools functions to match StatFn signature.\n",
    "# Tip: use functools.partial to pre-set rate, data_type, taus, overlapping, etc.\n",
    "\n",
    "# Type: any callable that takes your prepared data and returns (taus, values, errors_or_None)\n",
    "StatFn = Callable[[np.ndarray], Tuple[np.ndarray, np.ndarray, Optional[np.ndarray]]]\n",
    "\n",
    "# TimeLab uses OADEV, so let's not use the non-overlapping ADEV\n",
    "#def wrap_adev(rate: float = 1.0, data_type: str = \"phase\", taus: Optional[Iterable[float]] = None, **kwargs) -> StatFn:\n",
    "#    \"\"\"\n",
    "#    Returns a callable that takes 'data' and produces (taus, values, errors_or_None, n).\n",
    "#    \"\"\"\n",
    "#    def _fn(data: np.ndarray) -> Tuple[np.ndarray, np.ndarray, Optional[np.ndarray]]:\n",
    "#        # Many versions return a tuple: (taus, stat, stat_err, ns)\n",
    "#        # If yours returns a dict, adjust the extraction below accordingly.\n",
    "#        out = at.adev(data, rate=rate, data_type=data_type, taus=genTaus(len(data), winLen=2), **kwargs)\n",
    "#        try:\n",
    "#            tau, val, err, n = out  # common tuple form\n",
    "#        except Exception:\n",
    "#            assert False, \"adev should return a tuple or dict-like form\"\n",
    "#            # Fallback for dict-like forms; update keys to match your version\n",
    "#            tau = np.asarray(out.get(\"taus\") or out.get(\"tau\"))\n",
    "#            val = np.asarray(out.get(\"adev\") or out.get(\"adev\") or out.get(\"values\"))\n",
    "#            err = out.get(\"adev_err\") or out.get(\"adeverror\") or None\n",
    "#            if err is not None:\n",
    "#                err = np.asarray(err)\n",
    "#        return np.asarray(tau), np.asarray(val), (None if err is None else np.asarray(err)), n\n",
    "#    return _fn\n",
    "#\n",
    "#adev = wrap_adev()\n",
    "\n",
    "def wrap_oadev(rate: float = 1.0, data_type: str = \"phase\", taus: Optional[Iterable[float]] = None, **kwargs) -> StatFn:\n",
    "    \"\"\"\n",
    "    Returns a callable that takes 'data' and produces (taus, values, errors_or_None, n).\n",
    "    \"\"\"\n",
    "    def _fn(data: np.ndarray) -> Tuple[np.ndarray, np.ndarray, Optional[np.ndarray]]:\n",
    "        out = at.oadev(data, rate=rate, data_type=data_type, taus=genTaus(len(data), winLen=2), **kwargs)\n",
    "        try:\n",
    "            tau, val, err, n = out  # common tuple form\n",
    "        except Exception:\n",
    "            assert False, \"oadev should return a tuple or dict-like form\"\n",
    "            # Fallback for dict-like forms; update keys to match your version\n",
    "            tau = np.asarray(out.get(\"taus\") or out.get(\"tau\"))\n",
    "            val = np.asarray(out.get(\"oadev\") or out.get(\"oadev\") or out.get(\"values\"))\n",
    "            err = out.get(\"oadev_err\") or out.get(\"adeverror\") or None\n",
    "            if err is not None:\n",
    "                err = np.asarray(err)\n",
    "        return np.asarray(tau), np.asarray(val), (None if err is None else np.asarray(err)), n\n",
    "    return _fn\n",
    "\n",
    "oadev = wrap_oadev()\n",
    "\n",
    "def wrap_tdev(**kwargs) -> StatFn:\n",
    "    def _fn(data: np.ndarray):\n",
    "        out = at.tdev(data, rate=1.0, taus=genTaus(len(data), perDecade=30), **kwargs)\n",
    "        try:\n",
    "            tau, val, err, n = out\n",
    "        except Exception:\n",
    "            assert False, \"tdev should return a tuple or dict-like form\"\n",
    "            tau = np.asarray(out.get(\"taus\") or out.get(\"tau\"))\n",
    "            val = np.asarray(out.get(\"tdev\") or out.get(\"values\"))\n",
    "            err = out.get(\"tdev_err\") or None\n",
    "            if err is not None:\n",
    "                err = np.asarray(err)\n",
    "        return np.asarray(tau), np.asarray(val), (None if err is None else np.asarray(err)), n\n",
    "    return _fn\n",
    "\n",
    "tdev = wrap_tdev()\n",
    "\n",
    "def wrap_mtie(**kwargs) -> StatFn:\n",
    "    def _fn(data: np.ndarray):\n",
    "        out = at.mtie(data, rate=1.0, taus=genTaus(len(data), perDecade=30), **kwargs)\n",
    "        try:\n",
    "            tau, val, err, n = out\n",
    "        except Exception:\n",
    "            assert False, \"mtie should return a tuple or dict-like form\"\n",
    "            tau = np.asarray(out.get(\"taus\") or out.get(\"tau\"))\n",
    "            val = np.asarray(out.get(\"mtie\") or out.get(\"values\"))\n",
    "            err = out.get(\"mtie_err\") or None\n",
    "            if err is not None:\n",
    "                err = np.asarray(err)\n",
    "        return np.asarray(tau), np.asarray(val), (None if err is None else np.asarray(err)), n\n",
    "    return _fn\n",
    "\n",
    "mtie = wrap_mtie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statPlotStart(\n",
    "    statFn: Optional[StatFn] = tdev,\n",
    "    title: Optional[str] = None,\n",
    "    xlabel: str = r\"$\\tau$\",\n",
    "    ylabel: Optional[str] = None,\n",
    "    logx: bool = True,\n",
    "    logy: bool = True,\n",
    "    grid: bool = True,\n",
    "    figsize: Tuple[float, float] = (16, 9),\n",
    ") -> Tuple[plt.Figure, plt.Axes]:\n",
    "\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    if logx and logy:\n",
    "        ax.set_xscale(\"log\")\n",
    "        ax.set_yscale(\"log\")\n",
    "    elif logx:\n",
    "        ax.set_xscale(\"log\")\n",
    "    elif logy:\n",
    "        ax.set_yscale(\"log\")\n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=20)\n",
    "    ax.set_xlabel(xlabel, fontsize=20)\n",
    "    if ylabel is None:\n",
    "        if sameFunc(statFn, tdev):\n",
    "            ylabel = r\"$\\sigma_x(\\tau)$\"\n",
    "        elif sameFunc(statFn, oadev):\n",
    "            ylabel = r\"$\\sigma_y(\\tau)$\"\n",
    "        elif sameFunc(statFn, mtie):\n",
    "            ylabel = r\"MTIE($\\tau$)\"\n",
    "    ax.set_ylabel(ylabel, fontsize=20)\n",
    "    if grid:\n",
    "        ax.grid(True, which=\"both\", alpha=0.35)\n",
    "\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statPlotTrace(\n",
    "    ax: plt.Axes,\n",
    "    s: pd.Series,\n",
    "    statFn: StatFn,\n",
    "    secLimit: Optional[int] = sys.maxsize,\n",
    "    *,\n",
    "    label: Optional[str] = None,\n",
    "    errBars: bool = False,\n",
    "    # Matplotlib styling (pass whatever you like; e.g., color, linestyle, marker, alpha, linewidth ...)\n",
    "    **line_kwargs,\n",
    ") -> Tuple[np.ndarray, np.ndarray, Optional[np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Preprocesses the Series, calls statFn, then plots (taus, value) on ax.\n",
    "    Returns (taus, values, errors_or_None) for further use if needed.\n",
    "    \"\"\"\n",
    "    taus, vals, errs, n = statFn(s[:secLimit].dropna())  # Apply the statistic function to the Series, limited by secLimit\n",
    "\n",
    "    mult = 1e9 if sameFunc(statFn, tdev) or sameFunc(statFn, mtie) else 1.0  # Convert to nanoseconds if using TDEV\n",
    "    line = plt.loglog(taus, mult*vals, label=label, **line_kwargs)[0]\n",
    "    color = line.get_color()\n",
    "\n",
    "    if errBars:\n",
    "        goodN = n >= 10 # Ensure we have enough data points for the statistic to be meaningful\n",
    "        ax.errorbar(taus[goodN], mult*vals[goodN], yerr=mult*errs[goodN] if errs is not None else None, fmt='none', color=color, elinewidth=1.4,       # “web” thickness\n",
    "                capsize=2,            # “flange” length\n",
    "                capthick=1.4, **line_kwargs)\n",
    "    return taus, vals, errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def statPlotFinish(\n",
    "    ax: plt.Axes,\n",
    "    statFn: Optional[StatFn] = tdev,\n",
    "    legend: bool = True,\n",
    "    legend_loc: str = \"best\",\n",
    "    tight_layout: bool = False,\n",
    "):\n",
    "    if legend:\n",
    "        ax.legend(loc=legend_loc, fontsize=18)\n",
    "    if tight_layout:\n",
    "        ax.figure.tight_layout()\n",
    "    ax.tick_params(axis='both', which='both', labelsize=14)\n",
    "\n",
    "    ax.grid(which=\"major\", linestyle=\"-\", linewidth=1.0, color=\"gray\")\n",
    "    ax.grid(which=\"minor\", linestyle=\"--\", linewidth=1.0, color=\"lightgray\")\n",
    "\n",
    "    ax.xaxis.set_major_formatter(FuncFormatter(lambda x, _: f\"{x:g} s\"))\n",
    "\n",
    "    base_font = float(plt.rcParams.get(\"font.size\", 10))\n",
    "    annotation_font = max(base_font * 0.85, 10)\n",
    "    box_font = max(base_font * 0.9, 10)\n",
    "\n",
    "    if sameFunc(statFn, tdev) or sameFunc(statFn, mtie):\n",
    "        def _format_ns(value: float, _tick: int) -> str:\n",
    "            if value <= 0:\n",
    "                return \"XXX\"\n",
    "            if value >= 1:\n",
    "                return f\"{value:.0f} ns\"\n",
    "            if value >= 1e-3:\n",
    "                return f\"{1e3*value:3.0f} ps\"\n",
    "            return f\"D{value:.1e} ns\"\n",
    "\n",
    "        ns_formatter = FuncFormatter(_format_ns)\n",
    "        ax.yaxis.set_major_formatter(ns_formatter)\n",
    "        ax.yaxis.set_minor_formatter(ns_formatter)\n",
    "        #ax.yaxis.set_major_locator(MaxNLocator(nbins=10, prune='lower', min_n_ticks=5)) # AI suggestion\n",
    "        #ax.yaxis.set_minor_locator(MaxNLocator(5))\n",
    "\n",
    "        ymin, ymax = ax.get_ylim()\n",
    "        if ymin < 0.1:\n",
    "            yShadeMin = ymin\n",
    "            yShadeMax = 0.1\n",
    "            ax.axhspan(yShadeMin, yShadeMax, color=\"lightgray\", alpha=0.3)\n",
    "\n",
    "            y_center = np.sqrt(yShadeMin * yShadeMax)\n",
    "            x_limits = ax.get_xlim()\n",
    "            x_center = np.sqrt(x_limits[0] * x_limits[1])\n",
    "            ax.text(\n",
    "                x_center,\n",
    "                y_center,\n",
    "                \"RMS Jitter Floor of TAPR TICC\",\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                fontsize=annotation_font,\n",
    "                color=\"black\",\n",
    "                bbox=dict(facecolor=\"white\", alpha=0.7, edgecolor=\"none\"),\n",
    "            )\n",
    "            ax.set_ylim(ymin, ymax)\n",
    "\n",
    "    ax.text(\n",
    "        0.95,\n",
    "        0.1,\n",
    "        \"Instrument: TAPR TICC\\nReference: Geppetto GPSDO with OH300 5ppb OCXO\",\n",
    "        ha=\"right\",\n",
    "        va=\"bottom\",\n",
    "        multialignment=\"left\",\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=box_font,\n",
    "        bbox=dict(\n",
    "            facecolor=\"white\",\n",
    "            edgecolor=\"black\",\n",
    "            boxstyle=\"round,pad=0.3\",\n",
    "        ),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = statPlotStart(title = r\"Impact of u-blox F9T $\\mathtt{qErr}$ Corrections on TDEV($\\tau$)\")\n",
    "\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedPos1'].rcFracA    , tdev, secLimit=200000, label='Uncorrected', linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedPos1'].rcFracCorrA, tdev, secLimit=200000, label='Corrected'  , linestyle='-', linewidth=2)\n",
    "statPlotFinish(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = statPlotStart(mtie, title = r\"Impact of u-blox F9T $\\mathtt{qErr}$ Corrections on MTIE($\\tau$)\")\n",
    "\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedPos1'].rcFracA    , mtie, secLimit=200000, label='Uncorrected', linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedPos1'].rcFracCorrA, mtie, secLimit=200000, label='Corrected'  , linestyle='-', linewidth=2)\n",
    "statPlotFinish(ax, mtie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = statPlotStart(oadev, title = r\"Impact of u-blox F9T $\\mathtt{qErr}$ Corrections on ADEV($\\tau$)\")\n",
    "\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedPos1'].rcFracA    , oadev, secLimit=200000, label='Uncorrected', linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedPos1'].rcFracCorrA, oadev, secLimit=200000, label='Corrected'  , linestyle='-', linewidth=2)\n",
    "statPlotFinish(ax, oadev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = statPlotStart(title = r\"Comparing TDEV for Two u-blox F9Ts with Common Anntenna and $\\mathtt{qErr}$ Corrections Individually and to Each Other\")\n",
    "\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracCorrA,  tdev, secLimit=300000, label='F9T-Bob'  , linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracCorrB,  tdev, secLimit=300000, label='F9T-PT'  , linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracCorrAB, tdev, secLimit=300000, label='F9T-Bob vs F9T-PT'  , linestyle='-', linewidth=2)\n",
    "statPlotFinish(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = statPlotStart(title = r\"Comparing MTIE for Two u-blox F9Ts with Common Anntenna and $\\mathtt{qErr}$ Corrections Individually and to Each Other\")\n",
    "\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracCorrA,  mtie, secLimit=30000, label='F9T-Bob'  , linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracCorrB,  mtie, secLimit=30000, label='F9T-PT'  , linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracCorrAB, mtie, secLimit=30000, label='F9T-Bob vs F9T-PT'  , linestyle='-', linewidth=2)\n",
    "statPlotFinish(ax, mtie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = statPlotStart(title = r\"Comparing ADEV for Two u-blox F9Ts with Common Anntenna and $\\mathtt{qErr}$ Corrections Individually and to Each Other\")\n",
    "\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracCorrA,  oadev, secLimit=30000, label='F9T-Bob'  , linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracCorrB,  oadev, secLimit=30000, label='F9T-PT'  , linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracCorrAB, oadev, secLimit=30000, label='F9T-Bob vs F9T-PT'  , linestyle='-', linewidth=2)\n",
    "statPlotFinish(ax, oadev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = statPlotStart(title = r\"Comparing TDEV for u-blox F9T and Meinberg M600 DHQ\")\n",
    "\n",
    "statPlotTrace(ax, epSec[epSec.bn=='ctiCns1'   ].rcFracB,     tdev, secLimit=300000, label='Jittery CNS Clock II'  , linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='f9tM600-2' ].rcFracB,     tdev, secLimit=300000, label='M600 DHQ'  , linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracA    , tdev, secLimit=300000, label='Uncorrected F9T-Bob', linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracCorrA, tdev, secLimit=300000, label='Corrected F9T-Bob'  , linestyle='dotted', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracB    , tdev, secLimit=300000, label='Uncorrected F9T-PT', linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracCorrB, tdev, secLimit=300000, label='Corrected F9T-PT'  , linestyle='dotted', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='ctiCns1'   ].rcFracA,     tdev, secLimit=300000, label='Cheap CTI OCXO'  , linestyle='-', linewidth=2)\n",
    "statPlotFinish(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = statPlotStart(title = r\"Comparing MTIE for u-blox F9T and Meinberg M600 DHQ\")\n",
    "\n",
    "statPlotTrace(ax, epSec[epSec.bn=='ctiCns1'   ].rcFracB,     mtie, secLimit=300000, label='Jittery CNS Clock II'  , linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='f9tM600-2' ].rcFracB,     mtie, secLimit=300000, label='M600 DHQ'  , linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracA    , mtie, secLimit=300000, label='Uncorrected F9T-Bob', linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracCorrA, mtie, secLimit=300000, label='Corrected F9T-Bob'  , linestyle='dotted', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracB    , mtie, secLimit=300000, label='Uncorrected F9T-PT', linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracCorrB, mtie, secLimit=300000, label='Corrected F9T-PT'  , linestyle='dotted', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='ctiCns1'   ].rcFracA,     mtie, secLimit=300000, label='Cheap CTI OCXO'  , linestyle='-', linewidth=2)\n",
    "statPlotFinish(ax, mtie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = statPlotStart(title = r\"Comparing ADEV for u-blox F9T and Meinberg M600 DHQ\")\n",
    "\n",
    "statPlotTrace(ax, epSec[epSec.bn=='ctiCns1'   ].rcFracB,     oadev, secLimit=300000, label='Jittery CNS Clock II'  , linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='f9tM600-2' ].rcFracB,     oadev, secLimit=300000, label='M600 DHQ'  , linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracA    , oadev, secLimit=300000, label='Uncorrected F9T-Bob', linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracCorrA, oadev, secLimit=300000, label='Corrected F9T-Bob'  , linestyle='dotted', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracB    , oadev, secLimit=300000, label='Uncorrected F9T-PT', linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracCorrB, oadev, secLimit=300000, label='Corrected F9T-PT'  , linestyle='dotted', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='ctiCns1'   ].rcFracA,     oadev, secLimit=300000, label='Cheap CTI OCXO'  , linestyle='-', linewidth=2)\n",
    "statPlotFinish(ax, oadev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = statPlotStart(title = r\"Comparing TDEV u-blox F9T as Config is Improved for Timing Performance\")\n",
    "\n",
    "statPlotTrace(ax, epSec[epSec.bn=='baseline5' ].rcFracA,     tdev, secLimit=300000, label='Factory Reset, Config Cleared'  , linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1ca1'].rcFracA    , tdev, secLimit=300000, label='Fixed Position L1 C/A, Run 1', linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracA    , tdev, secLimit=300000, label='Fixed Position L1 C/A & L5, Run 3', linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracCorrA, tdev, secLimit=300000, label='Fixed Position L1 C/A & L5, qErr Corrected'  , linestyle='dotted', linewidth=2)\n",
    "statPlotFinish(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = statPlotStart(title = r\"Comparing MTIE u-blox F9T as Config is Improved for Timing Performance\")\n",
    "\n",
    "statPlotTrace(ax, epSec[epSec.bn=='baseline5' ].rcFracA,     mtie, secLimit=300000, label='Factory Reset, Config Cleared'  , linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1ca1'].rcFracA    , mtie, secLimit=300000, label='Fixed Position L1 C/A, Run 1', linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracA    , mtie, secLimit=300000, label='Fixed Position L1 C/A & L5, Run 3', linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracCorrA, mtie, secLimit=300000, label='Fixed Position L1 C/A & L5, qErr Corrected'  , linestyle='dotted', linewidth=2)\n",
    "statPlotFinish(ax, mtie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "presentation_fonts = {\n",
    "    \"font.size\": 20,\n",
    "    \"axes.titlesize\": 24,\n",
    "    \"axes.labelsize\": 20,\n",
    "    \"legend.fontsize\": 18,\n",
    "    \"xtick.labelsize\": 18,\n",
    "    \"ytick.labelsize\": 18,\n",
    "}\n",
    "\n",
    "with plt.rc_context(presentation_fonts):\n",
    "    fig, ax = statPlotStart(title = r\"Comparing ADEV u-blox F9T as Config is Improved for Timing Performance\")\n",
    "\n",
    "    statPlotTrace(ax, epSec[epSec.bn=='baseline5' ].rcFracA,     oadev, secLimit=300000, label='Factory Reset, Config Cleared'  , linestyle='-', linewidth=2)\n",
    "    statPlotTrace(ax, epSec[epSec.bn=='fixedL1ca1'].rcFracA    , oadev, secLimit=300000, label='Fixed Position L1 C/A, Run 1', linestyle='-', linewidth=2)\n",
    "    statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracA    , oadev, secLimit=300000, label='Fixed Position L1 C/A & L5, Run 3', linestyle='-', linewidth=2)\n",
    "    statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracCorrA, oadev, secLimit=300000, label='Fixed Position L1 C/A & L5, qErr Corrected'  , linestyle='dotted', linewidth=2)\n",
    "    statPlotFinish(ax, oadev, tight_layout=True)\n",
    "    ax.tick_params(axis='both', which='both', labelsize=presentation_fonts[\"xtick.labelsize\"])\n",
    "    fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX Next:\n",
    "# . Clear output and checkpoint to git\n",
    "# . Try ADEV\n",
    "# . Try MTIE\n",
    "# . Plot M600\n",
    "# . Compare to baseline 5 without fixed position\n",
    "# . Confirm export to Timelab produces comparable plots\n",
    "# . Can you get error bars on TDEV and other plots?\n",
    "# Collecte data on AliExpress OCXO\n",
    "# Try overlaid TDEV and MTIE with gradient shading between them\n",
    "# See exactly what Taitien oscillator is on mini PT\n",
    "# Review other devices in talk proposal for data collection\n",
    "# Collect data on CNS Clock\n",
    "# Study time error histograms more carefully\n",
    "# Get deeper understanding of different deviations\n",
    "# Comapre ADEV to other reported results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Normal distribution parameters (ns)\n",
    "mu_ns = 0.0\n",
    "sigma_ns = 15.0  # 15 ns RMS\n",
    "\n",
    "# X range and PDF\n",
    "x = np.linspace(mu_ns - 6*sigma_ns, mu_ns + 6*sigma_ns, 2000)\n",
    "pdf = (1.0 / (np.sqrt(2*np.pi) * sigma_ns)) * np.exp(-0.5 * ((x - mu_ns)/sigma_ns)**2)\n",
    "\n",
    "# Plot\n",
    "#plt.figure(figsize=(24, 6))\n",
    "fig, ax = plt.subplots(figsize=(24, 6))\n",
    "ax.plot(x, pdf, lw=2)\n",
    "\n",
    "# Highlight 200 ps-wide (0.2 ns) vertical bands centered at 0, ±15 ns\n",
    "half_width_ns = 0.1  # ±100 ps\n",
    "for center in (0.0, -15.0, 15.0):\n",
    "    ax.axvspan(center - half_width_ns, center + half_width_ns, alpha=0.75)\n",
    "\n",
    "ax.set_xlabel(\"Time error (ns)\", fontsize=24)\n",
    "ax.set_ylabel(\"Probability density (1/ns)\", fontsize=24)\n",
    "ax.set_title(\"Normal(μ=0, σ=15 ns) with 200 ps-wide bands at 0 and ±15 ns\", fontsize=32)\n",
    "ax.set_xlim(mu_ns - 5*sigma_ns, mu_ns + 5*sigma_ns)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.xlim(-50, 50)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_sigma_ns = 1.0  # Standard deviation of each step; tweak to control walk volatility\n",
    "n_steps = 500\n",
    "seed = None  # Set to an int (e.g., 42) for reproducible walks\n",
    "\n",
    "rng = np.random.default_rng(seed)\n",
    "\n",
    "def random_walk(start_ns: float, step_sigma: float, steps: int, *, generator: np.random.Generator) -> np.ndarray:\n",
    "    \"\"\"Return a random walk (in ns) that begins at start_ns.\"\"\"\n",
    "    increments = generator.normal(loc=0.0, scale=step_sigma, size=steps)\n",
    "    return start_ns + np.concatenate(([0.0], np.cumsum(increments)))\n",
    "\n",
    "walk_neg = random_walk(-5.0, step_sigma_ns, n_steps, generator=rng)\n",
    "walk_pos = random_walk(10.0, step_sigma_ns, n_steps, generator=rng)\n",
    "step_index = np.arange(n_steps + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(step_index, walk_neg, label='Walk starting at -5 ns', linewidth=2)\n",
    "plt.plot(step_index, walk_pos, label='Walk starting at +10 ns', linewidth=2)\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Current Value (ns)')\n",
    "plt.title('Random Walks with Adjustable Step Size')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.35)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seconds = np.linspace(0, 86_400, 86_401)\n",
    "\n",
    "def utc_offset_ns(t: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Piecewise linear UTC offset (ns) for the evil GNSS clock.\"\"\"\n",
    "    offsets = np.empty_like(t)\n",
    "\n",
    "    night_mask = (t < 21_600)\n",
    "    offsets[night_mask] = -2.0 * t[night_mask]\n",
    "\n",
    "    morning_mask = (t >= 21_600) & (t < 43_200)\n",
    "    offsets[morning_mask] = -43_200.0 + 2.0 * (t[morning_mask] - 21_600.0)\n",
    "\n",
    "    afternoon_mask = (t >= 43_200) & (t < 64_800)\n",
    "    offsets[afternoon_mask] = 2.0 * (t[afternoon_mask] - 43_200.0)\n",
    "\n",
    "    evening_mask = t >= 64_800\n",
    "    offsets[evening_mask] = 43_200.0 - 2.0 * (t[evening_mask] - 64_800.0)\n",
    "\n",
    "    return offsets\n",
    "\n",
    "offset_ns = utc_offset_ns(seconds)\n",
    "offset_us = offset_ns / 1_000.0\n",
    "hours = seconds / 3_600.0\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.plot(hours, offset_us, linewidth=2, color='crimson')\n",
    "\n",
    "ax.set_xticks([0, 6, 12, 18, 24])\n",
    "ax.set_xticklabels(['12 AM', '6 AM', '12 PM', '6 PM', '12 AM'])\n",
    "\n",
    "ax.set_xlabel('Time of Day', fontsize=24)\n",
    "ax.set_ylabel('Offset from UTC (µs)', fontsize=24)\n",
    "ax.set_title('Evil GNSS Clock: Daily UTC Offset Profile', fontsize=32)\n",
    "ax.axhline(0, color='black', linewidth=1, linestyle='--', alpha=0.6)\n",
    "ax.grid(True, which='both', alpha=0.35)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.tight_layout()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
