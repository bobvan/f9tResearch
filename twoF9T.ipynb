{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import allantools\n",
    "from runData import runData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.precision\", 15)      # Show up to 15 decimal places\n",
    "#baseName = 'fixedL1l53'\n",
    "#baseName = 'baseline1'\n",
    "dirName  = 'labData/'\n",
    "#rowLimit = 2000 # Rows to keep after joining ticc and timTp samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Big Picture\n",
    "#   Read TICC data from runs of interest\n",
    "#   Process it, do simple analysis without timTp data\n",
    "#   Read timTp data\n",
    "#   Join with TICC data and analyze\n",
    "#   Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read TAPR TICC data into a dataframe, as captured to a file by ticc.py running on a host.\n",
    "# Events are rising edges of a PPS signal from a DUT, resulting in a timestamp on the TICC's reference clock.\n",
    "# Columns:\n",
    "#  ppsHostClock: Host clock when serial data for PPS event timestamp was read (ticc.py logs this in UTC)\n",
    "#  ppsRefClock:  Reference clock when PPS event happened (elapsed seconds since TICC started)\n",
    "#\n",
    "# The frequency of the TICC reference clock comes from an external 10 MHz source, a Geppetto Electronics GNSSDO in my case.\n",
    "# It should be almost exactly 1e7 times the PPS frequency, with an arbitray phase relationship.\n",
    "# So we expect the whole number portion of ppsRefClock to increment by 1 every second, while the fractional seconds jitter around\n",
    "# some slowly-changing phase offset.\n",
    "# Therefore, there's very little information in the whole seconds, while the fractional seconds contain the most interesting data.\n",
    "# And as the whole number grows with a floating point representation, precision is lost in the fractional digits.\n",
    "# So once we confirm the whole number of seconds is behaving as expected, we can drop it and focus on the fractional seconds.\n",
    "# Whatever slowly-changing phase offset exists, it won't impact the deviation metrics.\n",
    "# We treat the fractional seconds as an instantaneous (but nosiy) measurement of the phase error against the ref clock.\n",
    "#\n",
    "# There is a very small, but non-zero chance that the static phase offset plus the jitter causes sequential PPS timestamps to be\n",
    "# within the same second or more than one second apart, leading to missing or duplicate whole seconds.\n",
    "# Instead of properly handling whole seconds when this happens, just fail on assertions.\n",
    "def readTicc(baseName, chan):\n",
    "    ticcFile = f\"{dirName}/{baseName}.ticc{chan}.csv\"\n",
    "    ticcData = pd.read_csv(ticcFile, dtype={'ppsHostClock': str, 'ppsRefClock': str})\n",
    "\n",
    "    # Convert host timestamp string to UTC timestamp\n",
    "    ticcData[\"ppsHostClock\"] = pd.to_datetime(ticcData.ppsHostClock, utc=True)\n",
    "\n",
    "    # Assuming host clock sync is better than serialization latency of timestamp arriving,\n",
    "    # floor of host clock second will be the navigation epoch sencond.\n",
    "    # Will be used for later join with TIM-TP timestamps.\n",
    "    ticcData[\"epochSec\"] = ticcData[\"ppsHostClock\"].dt.floor(\"s\")\n",
    "\n",
    "\n",
    "    # Split ppsRefClock string into whole and fractional seconds\n",
    "    ticcData[[\"rcWhole\", \"rcFrac\"]] = ticcData.ppsRefClock.str.split(\".\", n=1, expand=True)\n",
    "\n",
    "    # Check for missing or duplicate whole seconds\n",
    "    ticcData['rcWhole'] = ticcData['rcWhole'].astype(int)\n",
    "    expected = set(range(ticcData.rcWhole.min(), ticcData.rcWhole.max() + 1))\n",
    "    observed = set(ticcData.rcWhole)\n",
    "    missing = sorted(expected - observed)\n",
    "    duplicates = ticcData.rcWhole[ticcData.rcWhole.duplicated()].unique().tolist()\n",
    "    assert len(missing)    == 0, f\"Missing whole seconds in ticc{chan}: {missing}\"\n",
    "    assert len(duplicates) == 0, f\"Duplicate whole seconds in ticc{chan}: {duplicates}\"\n",
    "\n",
    "    # Convert ref clock fractional part from digit string to float\n",
    "    ticcData['rcFrac'] = \"0.\" + ticcData['rcFrac'].astype(str)\n",
    "    ticcData['rcFrac'] = ticcData['rcFrac'].astype(float)\n",
    "\n",
    "    # Also get fractional part of host clock\n",
    "    ticcData['hcFrac'] = (ticcData.ppsHostClock.astype('int64')-1e9*(ticcData.ppsHostClock.astype('int64')//1e9))/1e9\n",
    "\n",
    "    # With overly careful consideration of maintining floating point precision, get interval between PPS events on ref clock.\n",
    "    ticcData['rcTi'] = (ticcData.rcWhole-ticcData.rcWhole.shift(1)) + (ticcData.rcFrac - ticcData.rcFrac.shift(1)) # Time interval between refClock samples on ref clock\n",
    "\n",
    "    ticcData['bn'  ] = baseName\n",
    "    ticcData['dut' ] = runData[baseName][chan]\n",
    "    ticcData['chan'] = chan\n",
    "    return ticcData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "dfs.append(readTicc('fixedL1l52', 'A'))\n",
    "dfs.append(readTicc('fixedL1l52', 'B'))\n",
    "dfs.append(readTicc('fixedL1l53', 'A'))\n",
    "dfs.append(readTicc('fixedL1l53', 'B'))\n",
    "ticc = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticc.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticc\n",
    "# XXX next step: define function to generate statistics from selected rows of ticc, plot, and label them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring data from TICC channels for each run together for each ref clock second.\n",
    "ticcA = ticc[ticc.chan == 'A'][['bn', 'rcWhole', 'rcFrac', 'epochSec']]\n",
    "ticcB = ticc[ticc.chan == 'B'][['bn', 'rcWhole', 'rcFrac'            ]]\n",
    "\n",
    "# Perform inner join on bn and rcWhole\n",
    "rcSec = pd.merge(ticcA, ticcB, on=['bn', 'rcWhole'], suffixes=('A', 'B'))\n",
    "\n",
    "# Derive columns of interest from the TICC data.\n",
    "rcSec['rcFracAB'] = rcSec.rcFracA - rcSec.rcFracB  # Phase difference between the two channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcSec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bn in rcSec.bn.unique():\n",
    "    print(f\"Stats for run: {bn}\")\n",
    "    print(rcSec[rcSec.bn==bn].rcFracAB.describe()[1:]*1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beg = 1000\n",
    "end = 2000\n",
    "bn = 'fixedL1l53'\n",
    "plt.figure(figsize=(24, 6))\n",
    "plt.plot(rcSec[rcSec.bn==bn].epochSec[beg:end], rcSec[rcSec.bn==bn].rcFracAB[beg:end]*1e9, marker='.', linestyle='-', color='b')\n",
    "plt.title(f\"Phase Difference (rcFracAB) vs Epoch Second for Run {bn}\")\n",
    "plt.xlabel('Epoch Second')\n",
    "plt.ylabel('Phase Difference (rcFracAB)')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(22, 6))\n",
    "fig.canvas.draw()\n",
    "bbox = ax.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "widthPx = int(bbox.width*fig.dpi)\n",
    "print(\"Figure width in pixels:\", widthPx)\n",
    "print(fig.get_figwidth())\n",
    "plt.hist(1e9*(ticc[ticc.bn==bn].rcTi[beg:end]-1.0), bins=widthPx, color='blue', alpha=0.7)\n",
    "plt.title('Histogram of Time Error Between PPS Pulses')\n",
    "plt.xlabel('Time Error (ns)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.gca().xaxis.set_major_formatter(FuncFormatter(lambda y, _: f\"{y:g} ns\"))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTimTp(baseName, chan):\n",
    "    timTp = pd.read_csv(f\"{dirName}/{baseName}.timTp{chan}.csv\")\n",
    "\n",
    "    # Confirm expected values in constant columns, then drop them\n",
    "    assert (timTp['timeBase'   ] ==  1).all(), \"Not all rows in timTp.timeBase are equal to 1\"\n",
    "    assert (timTp['utc'        ] ==  1).all(), \"Not all rows in timTp.utc are equal to 1\"\n",
    "    assert (timTp['raim'       ] ==  2).all(), \"Not all rows in timTp.raim are equal to 2\"\n",
    "    assert (timTp['qErrInvalid'] ==  0).all(), \"Not all rows in timTp.qErrInvalid are equal to 0\"\n",
    "    assert (timTp['TpNotLocked'] ==  0).all(), \"Not all rows in timTp.TpNotLocked are equal to 0\"\n",
    "    assert (timTp['timeRefGnss'] == 15).all(), \"Not all rows in timTp.timeRefGnss are equal to 15\"\n",
    "    assert (timTp['utcStandard'] ==  3).all(), \"Not all rows in timTp.utcStandard are equal to  3\"\n",
    "    assert (timTp['towSubMS'   ] ==  0).all(), \"Not all rows in timTp.towSubMS are equal to  0\"\n",
    "    timTp.drop(columns=['timeBase', 'utc', 'raim', 'qErrInvalid', 'TpNotLocked', 'timeRefGnss', 'utcStandard', 'towSubMS'], inplace=True)\n",
    "\n",
    "    # Constants for time conversion\n",
    "    gps_epoch = pd.Timestamp(\"1980-01-06 00:00:00\", tz=\"UTC\")\n",
    "    leap_seconds = pd.Timedelta(seconds=18)  # current GPS-UTC offset (2025)\n",
    "\n",
    "    # Vectorized conversion from GPS week and TOW to epoch seconds\n",
    "    timTp[\"epochSec\"] = (\n",
    "        gps_epoch\n",
    "        + pd.to_timedelta(timTp.week  * 7, unit=\"D\" )\n",
    "        + pd.to_timedelta(timTp.towMS    , unit=\"ms\")\n",
    "    )\n",
    "    timTp.drop(columns=['week', 'towMS'], inplace=True)\n",
    "\n",
    "    timTp['qErrFrac'] = timTp.qErr/1e12 # Convert qErr from picoseconds to seconds\n",
    "\n",
    "    timTp['bn'] = baseName\n",
    "    timTp['dut' ] = runData[baseName][chan]\n",
    "    timTp['chan'] = chan\n",
    "    return timTp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "dfs.append(readTimTp('fixedL1l52', 'A'))\n",
    "dfs.append(readTimTp('fixedL1l52', 'B'))\n",
    "dfs.append(readTimTp('fixedL1l53', 'A'))\n",
    "dfs.append(readTimTp('fixedL1l53', 'B'))\n",
    "timTp = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timTp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring data from TIM-TP messages for each run together for each epoch second.\n",
    "timTpA = timTp[timTp.chan == 'A'][['bn', 'epochSec', 'qErr', 'qErrFrac']]\n",
    "timTpB = timTp[timTp.chan == 'B'][['bn', 'epochSec', 'qErr', 'qErrFrac']]\n",
    "\n",
    "# Perform inner join on bn and epoch second\n",
    "epSec = pd.merge(timTpA, timTpB, on=['bn', 'epochSec'], suffixes=('A', 'B'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge TICC data from above with TIM-TP data on epoch second.\n",
    "epSec = pd.merge(epSec, rcSec, on=['bn', 'epochSec'], how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epSec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct rcFrac with qErr\n",
    "epSec['rcFracCorrA'] = epSec.rcFracA+epSec.qErrFracA\n",
    "epSec['rcFracCorrB'] = epSec.rcFracB+epSec.qErrFracB\n",
    "\n",
    "# Corrected phase difference between the two channels\n",
    "epSec['rcFracCorrAB'] = epSec.rcFracCorrA - epSec.rcFracCorrB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epSec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bn in epSec.bn.unique():\n",
    "    print(f\"Stats for run: {bn}\")\n",
    "    print(epSec[epSec.bn==bn][:1000].rcFracCorrAB.describe()[1:]*1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If I have two series of PPS timestamps from imperfect clocks and I want to compare how well they track each other, paying less attention to the absolute phase error and more to the relative phase error, are there statistical analysis methods like Allan deviation that I can apply to the difference between clocks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beg = 11000\n",
    "end = 11500\n",
    "bn = 'fixedL1l53'\n",
    "plt.figure(figsize=(24, 6))\n",
    "plt.plot(epSec[epSec.bn==bn].epochSec[beg:end], epSec[epSec.bn==bn].rcFracAB[beg:end]*1e9, marker='.', linestyle='-', color='b')\n",
    "plt.plot(epSec[epSec.bn==bn].epochSec[beg:end], epSec[epSec.bn==bn].rcFracCorrAB[beg:end]*1e9, marker='.', linestyle='-', color='r')\n",
    "plt.title(f\"Phase Difference (epFracAB) vs Epoch Second for Run {bn}\")\n",
    "plt.xlabel('Epoch Second')\n",
    "plt.ylabel('Phase Difference (epFracAB)')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
