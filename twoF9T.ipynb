{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import allantools as at\n",
    "from typing import Callable, Iterable, Optional, Tuple\n",
    "from functools import partial\n",
    "from runData import runData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.precision\", 15)      # Show up to 15 decimal places\n",
    "#baseName = 'fixedL1l53'\n",
    "#baseName = 'baseline1'\n",
    "dirName  = 'labData/'\n",
    "#rowLimit = 2000 # Rows to keep after joining ticc and timTp samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Big Picture\n",
    "#   Read TICC data from runs of interest\n",
    "#   Process it, do simple analysis without timTp data\n",
    "#   Read timTp data\n",
    "#   Join with TICC data and analyze\n",
    "#   Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read TAPR TICC data into a dataframe, as captured to a file by ticc.py running on a host.\n",
    "# Events are rising edges of a PPS signal from a DUT, resulting in a timestamp on the TICC's reference clock.\n",
    "# Columns:\n",
    "#  ppsHostClock: Host clock when serial data for PPS event timestamp was read (ticc.py logs this in UTC)\n",
    "#  ppsRefClock:  Reference clock when PPS event happened (elapsed seconds since TICC started)\n",
    "#\n",
    "# The frequency of the TICC reference clock comes from an external 10 MHz source, a Geppetto Electronics GNSSDO in my case.\n",
    "# It should be almost exactly 1e7 times the PPS frequency, with an arbitray phase relationship.\n",
    "# So we expect the whole number portion of ppsRefClock to increment by 1 every second, while the fractional seconds jitter around\n",
    "# some slowly-changing phase offset.\n",
    "# Therefore, there's very little information in the whole seconds, while the fractional seconds contain the most interesting data.\n",
    "# And as the whole number grows with a floating point representation, precision is lost in the fractional digits.\n",
    "# So once we confirm the whole number of seconds is behaving as expected, we can drop it and focus on the fractional seconds.\n",
    "# Whatever slowly-changing phase offset exists, it won't impact the deviation metrics.\n",
    "# We treat the fractional seconds as an instantaneous (but nosiy) measurement of the phase error against the ref clock.\n",
    "#\n",
    "# There is a very small, but non-zero chance that the static phase offset plus the jitter causes sequential PPS timestamps to be\n",
    "# within the same second or more than one second apart, leading to missing or duplicate whole seconds.\n",
    "# Instead of properly handling whole seconds when this happens, just fail on assertions.\n",
    "def readTicc(baseName, chan):\n",
    "    ticcFile = f\"{dirName}/{baseName}.ticc{chan}.csv\"\n",
    "    ticcData = pd.read_csv(ticcFile, dtype={'ppsHostClock': str, 'ppsRefClock': str})\n",
    "\n",
    "    # Convert host timestamp string to UTC timestamp\n",
    "    ticcData[\"ppsHostClock\"] = pd.to_datetime(ticcData.ppsHostClock, utc=True)\n",
    "\n",
    "    # Assuming host clock sync is better than serialization latency of timestamp arriving,\n",
    "    # floor of host clock second will be the navigation epoch sencond.\n",
    "    # Will be used for later join with TIM-TP timestamps.\n",
    "    ticcData[\"epochSec\"] = ticcData[\"ppsHostClock\"].dt.floor(\"s\")\n",
    "\n",
    "\n",
    "    # Split ppsRefClock string into whole and fractional seconds\n",
    "    ticcData[[\"rcWhole\", \"rcFrac\"]] = ticcData.ppsRefClock.str.split(\".\", n=1, expand=True)\n",
    "\n",
    "    # Check for missing or duplicate whole seconds\n",
    "    ticcData['rcWhole'] = ticcData['rcWhole'].astype(int)\n",
    "    expected = set(range(ticcData.rcWhole.min(), ticcData.rcWhole.max() + 1))\n",
    "    observed = set(ticcData.rcWhole)\n",
    "    missing = sorted(expected - observed)\n",
    "    duplicates = ticcData.rcWhole[ticcData.rcWhole.duplicated()].unique().tolist()\n",
    "    assert len(missing)    == 0, f\"Missing whole seconds in ticc{chan}: {missing}\"\n",
    "    assert len(duplicates) == 0, f\"Duplicate whole seconds in ticc{chan}: {duplicates}\"\n",
    "\n",
    "    # Convert ref clock fractional part from digit string to float\n",
    "    ticcData['rcFrac'] = \"0.\" + ticcData['rcFrac'].astype(str)\n",
    "    ticcData['rcFrac'] = ticcData['rcFrac'].astype(float)\n",
    "\n",
    "    # Also get fractional part of host clock\n",
    "    ticcData['hcFrac'] = (ticcData.ppsHostClock.astype('int64')-1e9*(ticcData.ppsHostClock.astype('int64')//1e9))/1e9\n",
    "\n",
    "    # With overly careful consideration of maintining floating point precision, get interval between PPS events on ref clock.\n",
    "    ticcData['rcTi'] = (ticcData.rcWhole-ticcData.rcWhole.shift(1)) + (ticcData.rcFrac - ticcData.rcFrac.shift(1)) # Time interval between refClock samples on ref clock\n",
    "\n",
    "    ticcData['bn'  ] = baseName\n",
    "    ticcData['dut' ] = runData[baseName][chan]\n",
    "    ticcData['chan'] = chan\n",
    "    return ticcData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "dfs.append(readTicc('fixedL1l52', 'A'))\n",
    "dfs.append(readTicc('fixedL1l52', 'B'))\n",
    "dfs.append(readTicc('fixedL1l53', 'A'))\n",
    "dfs.append(readTicc('fixedL1l53', 'B'))\n",
    "dfs.append(readTicc('fixedPos1', 'A'))\n",
    "dfs.append(readTicc('fixedPos2', 'A'))\n",
    "ticc = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticc\n",
    "# XXX next step: define function to generate statistics from selected rows of ticc, plot, and label them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring data from TICC channels for each run together for each ref clock second.\n",
    "ticcA = ticc[ticc.chan == 'A'][['bn', 'rcWhole', 'rcFrac', 'epochSec']]\n",
    "ticcB = ticc[ticc.chan == 'B'][['bn', 'rcWhole', 'rcFrac'            ]]\n",
    "\n",
    "# Perform inner join on bn and rcWhole\n",
    "rcSec = pd.merge(ticcA, ticcB, on=['bn', 'rcWhole'], how='outer', suffixes=('A', 'B'))\n",
    "\n",
    "# Derive columns of interest from the TICC data.\n",
    "if ticcB.empty:\n",
    "    rcSec.drop(columns=['rcFracB'], inplace=True)\n",
    "else:\n",
    "    rcSec['rcFracAB'] = rcSec.rcFracA - rcSec.rcFracB  # Phase difference between the two channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticcB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcSec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX Fixme when run with no channel B\n",
    "beg = 1000\n",
    "end = 2000\n",
    "bn = 'fixedL1l53'\n",
    "plt.figure(figsize=(24, 6))\n",
    "plt.plot(rcSec[rcSec.bn==bn].epochSec[beg:end], rcSec[rcSec.bn==bn].rcFracAB[beg:end]*1e9, marker='.', linestyle='-', color='b')\n",
    "plt.title(f\"Phase Difference (rcFracAB) vs Epoch Second for Run {bn}\")\n",
    "plt.xlabel('Epoch Second')\n",
    "plt.ylabel('Phase Difference (rcFracAB)')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(22, 6))\n",
    "fig.canvas.draw()\n",
    "bbox = ax.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "widthPx = int(bbox.width*fig.dpi)\n",
    "print(\"Figure width in pixels:\", widthPx)\n",
    "print(fig.get_figwidth())\n",
    "for bn in ticc.bn.unique():\n",
    "    ticcSubset = ticc[ticc.bn == bn]\n",
    "    plt.hist(1e9*(ticcSubset.rcTi-1.0), bins=widthPx, label=bn, alpha=0.5)\n",
    "#plt.hist(1e9*(ticc[ticc.bn==bn].rcTi[beg:end]-1.0), bins=widthPx, color='blue', alpha=0.7)\n",
    "plt.title('Histogram of Time Error Between PPS Pulses')\n",
    "plt.xlabel('Time Error (ns)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.legend()\n",
    "plt.gca().xaxis.set_major_formatter(FuncFormatter(lambda y, _: f\"{y:g} ns\"))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTimTp(baseName, chan):\n",
    "    timTp = pd.read_csv(f\"{dirName}/{baseName}.timTp{chan}.csv\")\n",
    "\n",
    "    # Confirm expected values in constant columns, then drop them\n",
    "    assert (timTp['timeBase'   ] ==  1).all(), \"Not all rows in timTp.timeBase are equal to 1\"\n",
    "    assert (timTp['utc'        ] ==  1).all(), \"Not all rows in timTp.utc are equal to 1\"\n",
    "    assert (timTp['raim'       ] ==  2).all(), \"Not all rows in timTp.raim are equal to 2\"\n",
    "    assert (timTp['qErrInvalid'] ==  0).all(), \"Not all rows in timTp.qErrInvalid are equal to 0\"\n",
    "    assert (timTp['TpNotLocked'] ==  0).all(), \"Not all rows in timTp.TpNotLocked are equal to 0\"\n",
    "    assert (timTp['timeRefGnss'] == 15).all(), \"Not all rows in timTp.timeRefGnss are equal to 15\"\n",
    "    assert (timTp['utcStandard'] ==  3).all(), \"Not all rows in timTp.utcStandard are equal to  3\"\n",
    "    assert (timTp['towSubMS'   ] ==  0).all(), \"Not all rows in timTp.towSubMS are equal to  0\"\n",
    "    timTp.drop(columns=['timeBase', 'utc', 'raim', 'qErrInvalid', 'TpNotLocked', 'timeRefGnss', 'utcStandard', 'towSubMS'], inplace=True)\n",
    "\n",
    "    # Constants for time conversion\n",
    "    gps_epoch = pd.Timestamp(\"1980-01-06 00:00:00\", tz=\"UTC\")\n",
    "    leap_seconds = pd.Timedelta(seconds=18)  # current GPS-UTC offset (2025)\n",
    "\n",
    "    # Vectorized conversion from GPS week and TOW to epoch seconds\n",
    "    timTp[\"epochSec\"] = (\n",
    "        gps_epoch\n",
    "        + pd.to_timedelta(timTp.week  * 7, unit=\"D\" )\n",
    "        + pd.to_timedelta(timTp.towMS    , unit=\"ms\")\n",
    "    )\n",
    "    timTp.drop(columns=['week', 'towMS'], inplace=True)\n",
    "\n",
    "    timTp['qErrFrac'] = timTp.qErr/1e12 # Convert qErr from picoseconds to seconds\n",
    "\n",
    "    timTp['bn'] = baseName\n",
    "    timTp['dut' ] = runData[baseName][chan]\n",
    "    timTp['chan'] = chan\n",
    "    return timTp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "dfs.append(readTimTp('fixedL1l52', 'A'))\n",
    "dfs.append(readTimTp('fixedL1l52', 'B'))\n",
    "dfs.append(readTimTp('fixedL1l53', 'A'))\n",
    "dfs.append(readTimTp('fixedL1l53', 'B'))\n",
    "dfs.append(readTimTp('fixedPos1', 'A'))\n",
    "dfs.append(readTimTp('fixedPos2', 'A'))\n",
    "timTp = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timTp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring data from TIM-TP messages for each run together for each epoch second.\n",
    "timTpA = timTp[timTp.chan == 'A'][['bn', 'epochSec', 'qErr', 'qErrFrac']]\n",
    "timTpB = timTp[timTp.chan == 'B'][['bn', 'epochSec', 'qErr', 'qErrFrac']]\n",
    "\n",
    "# Perform inner join on bn and epoch second\n",
    "epSec = pd.merge(timTpA, timTpB, on=['bn', 'epochSec'], how='outer', suffixes=('A', 'B'))\n",
    "if timTpB.empty:\n",
    "    epSec.drop(columns=['qErrB'    ], inplace=True)\n",
    "    epSec.drop(columns=['qErrFracB'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge TICC data from above with TIM-TP data on epoch second.\n",
    "epSec = pd.merge(epSec, rcSec, on=['bn', 'epochSec'], how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epSec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct rcFrac with qErr\n",
    "epSec['rcFracCorrA'] = epSec.rcFracA+epSec.qErrFracA\n",
    "\n",
    "if not timTpB.empty:\n",
    "    epSec['rcFracCorrB'] = epSec.rcFracB+epSec.qErrFracB\n",
    "    # Corrected phase difference between the two channels\n",
    "    epSec['rcFracCorrAB'] = epSec.rcFracCorrA - epSec.rcFracCorrB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epSec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not timTpB.empty:\n",
    "    for bn in epSec.bn.unique():\n",
    "        print(f\"Stats for run: {bn}\")\n",
    "        print(epSec[epSec.bn==bn][:1000].rcFracCorrAB.describe()[1:]*1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If I have two series of PPS timestamps from imperfect clocks and I want to compare how well they track each other, paying less attention to the absolute phase error and more to the relative phase error, are there statistical analysis methods like Allan deviation that I can apply to the difference between clocks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beg = 11000\n",
    "end = 11500\n",
    "bn = 'fixedL1l53'\n",
    "plt.figure(figsize=(24, 6))\n",
    "plt.plot(epSec[epSec.bn==bn].epochSec[beg:end], epSec[epSec.bn==bn].rcFracAB[beg:end]*1e9, marker='.', linestyle='-', color='b')\n",
    "plt.plot(epSec[epSec.bn==bn].epochSec[beg:end], epSec[epSec.bn==bn].rcFracCorrAB[beg:end]*1e9, marker='.', linestyle='-', color='r')\n",
    "plt.title(f\"Phase Difference (epFracAB) vs Epoch Second for Run {bn}\")\n",
    "plt.xlabel('Epoch Second')\n",
    "plt.ylabel('Phase Difference (epFracAB)')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statPlotStart(\n",
    "    title: Optional[str] = None,\n",
    "    xlabel: str = r\"$\\tau$\",\n",
    "    ylabel: Optional[str] = r\"$\\sigma_x(\\tau)$\",\n",
    "    logx: bool = True,\n",
    "    logy: bool = True,\n",
    "    grid: bool = True,\n",
    "    figsize: Tuple[float, float] = (16, 9),\n",
    ") -> Tuple[plt.Figure, plt.Axes]:\n",
    "\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    if logx and logy:\n",
    "        ax.set_xscale(\"log\")\n",
    "        ax.set_yscale(\"log\")\n",
    "    elif logx:\n",
    "        ax.set_xscale(\"log\")\n",
    "    elif logy:\n",
    "        ax.set_yscale(\"log\")\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    if ylabel:\n",
    "        ax.set_ylabel(ylabel)\n",
    "    if grid:\n",
    "        ax.grid(True, which=\"both\", alpha=0.35)\n",
    "\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type: any callable that takes your prepared data and returns (taus, values, errors_or_None)\n",
    "StatFn = Callable[[np.ndarray], Tuple[np.ndarray, np.ndarray, Optional[np.ndarray]]]\n",
    "\n",
    "def statPlotTrace(\n",
    "    ax: plt.Axes,\n",
    "    s: pd.Series,\n",
    "    stat_fn: StatFn,\n",
    "    secLimit: Optional[int] = sys.maxsize,\n",
    "    *,\n",
    "    label: Optional[str] = None,\n",
    "    # Matplotlib styling (pass whatever you like; e.g., color, linestyle, marker, alpha, linewidth ...)\n",
    "    **line_kwargs,\n",
    ") -> Tuple[np.ndarray, np.ndarray, Optional[np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Preprocesses the Series, calls stat_fn, then plots (taus, value) on ax.\n",
    "    Returns (taus, values, errors_or_None) for further use if needed.\n",
    "    \"\"\"\n",
    "    taus, vals, errs = stat_fn(s[:secLimit])  # Apply the statistic function to the Series, limited by secLimit\n",
    "\n",
    "    # Plot the statistic (errs unused here; you can add errorbars if desired)\n",
    "    # ax.plot(taus, 1e9*vals, label=label, **line_kwargs)\n",
    "    plt.loglog(taus, 1e9*vals, label=label, **line_kwargs)\n",
    "    return taus, vals, errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statPlotFinish(\n",
    "    ax: plt.Axes,\n",
    "    legend: bool = True,\n",
    "    legend_loc: str = \"best\",\n",
    "    tight_layout: bool = False,\n",
    "):\n",
    "    if legend:\n",
    "        ax.legend(loc=legend_loc)\n",
    "    if tight_layout:\n",
    "        ax.figure.tight_layout()\n",
    "\n",
    "    #plt.annotate(f\"Uncorrected TDEV(1 s): {tdevUcNs[0]:.3f} ns\", xy=(1, tdevUcNs[0]), xytext=(1.1, 3),\n",
    "    #            arrowprops=dict(arrowstyle=\"fancy\", ec=\"black\", fc=\"yellow\", lw=0.5))\n",
    "    #plt.annotate(f\"Corrected TDEV(1 s): {tdevCorrNs[0]:.3f} ns\", xy=(1, tdevCorrNs[0]), xytext=(1.1, 0.25),\n",
    "    #            arrowprops=dict(arrowstyle=\"fancy\", ec=\"black\", fc=\"yellow\", lw=0.5))\n",
    "\n",
    "    plt.grid(which=\"major\", linestyle=\"-\" , linewidth=1.0, color=\"gray\"     )\n",
    "    plt.grid(which=\"minor\", linestyle=\"--\", linewidth=1.0, color=\"lightgray\")\n",
    "\n",
    "    plt.gca().xaxis.set_major_formatter(FuncFormatter(lambda x, _: f\"{x:g} s\"))\n",
    "    plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda y, _: f\"{y:g} ns\"))\n",
    "\n",
    "    # Shade noise floor\n",
    "    ymin, ymax = plt.ylim() # Save limits before shading\n",
    "    yShadeMin = ymin\n",
    "    yShadeMax = 0.1\n",
    "    plt.axhspan(yShadeMin, yShadeMax, color=\"lightgray\", alpha=0.3)\n",
    "\n",
    "    # Add label centered inside shaded region, remembering that geometric mean is midpoint on log scales\n",
    "    y_center = np.sqrt(yShadeMin * yShadeMax)  # geometric mean for log scale\n",
    "    x_center = np.sqrt(plt.xlim()[0] * plt.xlim()[1])  # vertical center in log scale\n",
    "    plt.text(\n",
    "        x_center, y_center, \"RMS Jitter Floor of TAPR TICC\",\n",
    "        ha=\"center\", va=\"center\",\n",
    "        fontsize=10, color=\"black\",\n",
    "        bbox=dict(facecolor=\"white\", alpha=0.7, edgecolor=\"none\")\n",
    "    )\n",
    "    plt.ylim(ymin, ymax) # Restore limits after shading\n",
    "\n",
    "    plt.text(\n",
    "        0.95, 0.1,                # X & Y position in axes fraction (0–1)\n",
    "        \"Instrument: TAPR TICC\\nReference: Geppetto GPSDO with OH300 5ppb OCXO\",\n",
    "        ha=\"right\", va=\"bottom\",   # Align to lower-right corner\n",
    "        multialignment=\"left\",\n",
    "        transform=plt.gca().transAxes,  # ✅ Use axes fraction (not data coords)\n",
    "        fontsize=10,\n",
    "        bbox=dict(\n",
    "            facecolor=\"white\",     # Background color\n",
    "            edgecolor=\"black\",     # Border color\n",
    "            boxstyle=\"round,pad=0.3\"  # Rounded box with padding\n",
    "        )\n",
    "    )\n",
    "    #    return ax.figure, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapters — Wrap allantools functions to match StatFn signature.\n",
    "# Tip: use functools.partial to pre-set rate, data_type, taus, overlapping, etc.\n",
    "\n",
    "def wrap_oadev(rate: float = 1.0, data_type: str = \"phase\", taus: Optional[Iterable[float]] = None, **kwargs) -> StatFn:\n",
    "    \"\"\"\n",
    "    Returns a callable that takes 'data' and produces (taus, values, errors_or_None).\n",
    "    \"\"\"\n",
    "    def _fn(data: np.ndarray) -> Tuple[np.ndarray, np.ndarray, Optional[np.ndarray]]:\n",
    "        # Many versions return a tuple: (taus, stat, stat_err, ns)\n",
    "        # If yours returns a dict, adjust the extraction below accordingly.\n",
    "        out = at.oadev(data, rate=rate, data_type=data_type, taus=taus, **kwargs)\n",
    "        try:\n",
    "            tau, val, err, _ = out  # common tuple form\n",
    "        except Exception:\n",
    "            # Fallback for dict-like forms; update keys to match your version\n",
    "            tau = np.asarray(out.get(\"taus\") or out.get(\"tau\"))\n",
    "            val = np.asarray(out.get(\"oadev\") or out.get(\"adev\") or out.get(\"values\"))\n",
    "            err = out.get(\"oadev_err\") or out.get(\"adeverror\") or None\n",
    "            if err is not None:\n",
    "                err = np.asarray(err)\n",
    "        return np.asarray(tau), np.asarray(val), (None if err is None else np.asarray(err))\n",
    "    return _fn\n",
    "\n",
    "def wrap_tdev(rate: float = 1.0, taus: Optional[Iterable[float]] = 'all', **kwargs) -> StatFn:\n",
    "    def _fn(data: np.ndarray):\n",
    "        out = at.tdev(data, rate=1.0, taus=taus, **kwargs)\n",
    "        try:\n",
    "            tau, val, err, _ = out\n",
    "        except Exception:\n",
    "            tau = np.asarray(out.get(\"taus\") or out.get(\"tau\"))\n",
    "            val = np.asarray(out.get(\"tdev\") or out.get(\"values\"))\n",
    "            err = out.get(\"tdev_err\") or None\n",
    "            if err is not None:\n",
    "                err = np.asarray(err)\n",
    "        return np.asarray(tau), np.asarray(val), (None if err is None else np.asarray(err))\n",
    "    return _fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = statPlotStart(title = r\"Impact of u-blox F9T $\\mathtt{qErr}$ Corrections on TDEV($\\tau$)\")\n",
    "\n",
    "tdev = wrap_tdev(rate=1.0, taus='all')\n",
    "\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedPos1'].rcFracA    , tdev, secLimit=2000, label='Uncorrected', linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedPos1'].rcFracCorrA, tdev, secLimit=2000, label='Corrected'  , linestyle='-', linewidth=2)\n",
    "statPlotFinish(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = statPlotStart(title = r\"Comparing Two u-blox F9T $\\mathtt{qErr}$ Corrections on TDEV($\\tau$)\")\n",
    "\n",
    "tdev = wrap_tdev(rate=1.0, taus='all')\n",
    "\n",
    "#statPlotTrace(ax, epSec[epSec.bn=='fixedL1l52'].rcFracA    , tdev, secLimit=8000, label='Run 2 Uncorrected Bob', linestyle='-', linewidth=2)\n",
    "#statPlotTrace(ax, epSec[epSec.bn=='fixedL1l52'].rcFracB    , tdev, secLimit=8000, label='Run 2 Uncorrected PT', linestyle='-', linewidth=2)\n",
    "#statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracA    , tdev, secLimit=8000, label='Run 3 Uncorrected Bob', linestyle='-', linewidth=2)\n",
    "#statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracB    , tdev, secLimit=8000, label='Run 3 Uncorrected PT', linestyle='-', linewidth=2)\n",
    "\n",
    "# Same\n",
    "#statPlotTrace(ax, epSec[epSec.bn=='fixedL1l52'].rcFracCorrA, tdev, secLimit=3000, label='Run 2 Corrected Bob'  , linestyle='-', linewidth=2)\n",
    "#statPlotTrace(ax, epSec[epSec.bn=='fixedL1l52'].rcFracCorrB, tdev, secLimit=3000, label='Run 2 Corrected PT'  , linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracCorrA, tdev, secLimit=3000, label='Run 3 Corrected Bob'  , linestyle='-', linewidth=2)\n",
    "# Different\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracCorrB, tdev, secLimit=3000, label='Run 3 Corrected PT'  , linestyle='-', linewidth=2)\n",
    "\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l52'].rcFracCorrAB.dropna(), tdev, secLimit=3000, label='Run 2 Corrected AB'  , linestyle='-', linewidth=2)\n",
    "statPlotTrace(ax, epSec[epSec.bn=='fixedL1l53'].rcFracCorrAB.dropna(), tdev, secLimit=3000, label='Run 3 Corrected AB'  , linestyle='-', linewidth=2)\n",
    "statPlotFinish(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX Next: clear output and checkpoint to git\n",
    "# Try ADEV and MTIE\n",
    "# Plot M600\n",
    "# Collect data on CNS Clock\n",
    "# Compare to baseline 5 without fixed position\n",
    "# Collecte data on AliExpress OCXO\n",
    "# Review other devices in talk proposal for data collection\n",
    "# Study time error histograms more carefully\n",
    "# Can you get error bars on TDEV and other plots?\n",
    "# Get deeper understanding of different deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epSec[epSec.bn=='fixedL1l52'].rcFracCorrAB.dropna()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
